{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1nUlfrVx6lb1MDlvEd_gg9AvqG2BuSTI-",
      "authorship_tag": "ABX9TyOEsv+9M1cotsUBakYUREaJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cliffochi/aviva_data_science_course/blob/main/scratch_train_test_split.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manual implementation"
      ],
      "metadata": {
        "id": "gYDa_amd9KpH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YyhX4Pv986kQ"
      },
      "outputs": [],
      "source": [
        "def scratch_train_test_split(X, y, train_size=0.8, random_state=0):\n",
        "    np.random.seed(random_state)\n",
        "    y = y.reshape(-1, 1)\n",
        "    Xy = np.concatenate([X, y], axis=1)\n",
        "    size = len(Xy)\n",
        "    pick = int(np.round(size * train_size))\n",
        "    train_pick = np.random.choice(np.arange(size), pick, replace=False)\n",
        "    test_pick = np.delete(np.arange(size), train_pick)\n",
        "    train = Xy[train_pick, :]\n",
        "    test = Xy[test_pick, :]\n",
        "    X_train = train[:, 0:(Xy.shape[1] - y.shape[1])].reshape(-1, X.shape[1])\n",
        "    y_train = train[:, -y.shape[1]].reshape(-1, )\n",
        "    X_test = test[:, 0:(Xy.shape[1] - y.shape[1])].reshape(-1, X.shape[1])\n",
        "    y_test = test[:, -y.shape[1]].reshape(-1, )\n",
        "    return X_train, X_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the implementation is complete, we check that it works in our local environment. We will use the Ayame data set here. Checking at this stage is also frequently done in practice, and is an important task for finding errors early."
      ],
      "metadata": {
        "id": "6ZC3HSRo_54D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "X_train, X_test, y_train, y_test = scratch_train_test_split(X, y)\n",
        "print(f'X', X.shape)\n",
        "print(f'y', y.shape)\n",
        "print(f'X_train', X_train.shape)\n",
        "print(f'X_test', X_test.shape)\n",
        "print(f'y_train', y_train.shape)\n",
        "print(f'y_test', y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYJng8PtAAbW",
        "outputId": "28b1827d-9039-4638-b71a-949191137b11"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X (150, 4)\n",
            "y (150,)\n",
            "X_train (120, 4)\n",
            "X_test (30, 4)\n",
            "y_train (120,)\n",
            "y_test (30,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you get the expected output, you can say that the scratch implementation is working correctly. In this case, you can also confirm that you get the same output when you input the same data train_test_splitinto . This kind of comparison method is always an essential perspective for checking the validity of results."
      ],
      "metadata": {
        "id": "QUk6PUgBAWl6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a base model for classification problems"
      ],
      "metadata": {
        "id": "i7FwU6SXBO0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# obtaining iris data and creating a dataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris().data\n",
        "target = load_iris().target.reshape(-1, 1)\n",
        "iris = np.concatenate([data, target], axis=1)\n",
        "\n",
        "# Create DataFrame\n",
        "iris = pd.DataFrame(iris)\n",
        "\n",
        "# Create data for binary classification\n",
        "iris_X = iris.loc[iris[4] != 0, 0:3].values\n",
        "iris_y = iris.loc[iris[4] != 0, 4].values\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = scratch_train_test_split(X, y, train_size=0.8, random_state=0)"
      ],
      "metadata": {
        "id": "je7EVh9YACTu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a classifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "# Create a logistic regression model\n",
        "clf = SGDClassifier(loss=\"log_loss\")\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)"
      ],
      "metadata": {
        "id": "odzWLWOBB4n-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Create an SVM model\n",
        "clf = SVC(gamma='auto')\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)"
      ],
      "metadata": {
        "id": "BakRT6v8CPLx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Create a decision tree model\n",
        "clf = DecisionTreeClassifier(random_state=0)\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)"
      ],
      "metadata": {
        "id": "uB-JoI4hC0MY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "To evaluate the performance of a classifier, we use the following metrics: Measuring model performance is a computationally intensive process, but it is important for accurate evaluation."
      ],
      "metadata": {
        "id": "QqZMAsrcB2jG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# evaluation\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "NU9hq_hmC8hQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# evaluation\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "# Use 'weighted' for multiclass classification\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')"
      ],
      "metadata": {
        "id": "1z-F1VcJDQlT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regression"
      ],
      "metadata": {
        "id": "_t-70yR3GB5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data creation\n",
        "import pandas as pd # Load pandas\n",
        "train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/train.csv') # Load CSV\n",
        "X = train[['GrLivArea', 'YearBuilt']].values # Select explanatory variables\n",
        "y = train[['SalePrice']].values # Select objective variables\n",
        "X_train, X_test, y_train, y_test = scratch_train_test_split(X, y, train_size=0.8, random_state=0) # Split data"
      ],
      "metadata": {
        "id": "JaZaaszFDliD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pretreatment (standardization)\n",
        "from sklearn.preprocessing import StandardScaler # Load the class for standardization\n",
        "scaler = StandardScaler() # Instantiate the class\n",
        "scaler.fit(X_train) # Train the model\n",
        "X_train_std = scaler.transform(X_train) # Standardize the training data\n",
        "X_test_std = scaler.transform(X_test) # Standardize the test data\n"
      ],
      "metadata": {
        "id": "xuccaBLkGK16"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training the model\n",
        "from sklearn.linear_model import SGDRegressor # Load linear regression model (stochastic gradient descent)\n",
        "reg = SGDRegressor() # Instantiate the class\n",
        "reg.fit(X_train_std, y_train) # Train the model\n",
        "y_pred = reg.predict(X_test_std) # Run prediction"
      ],
      "metadata": {
        "id": "vPmOuwJpGtWj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluating the model\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "mse = mean_squared_error(y_test, y_pred) # Calculate MSE\n",
        "rmse = np.sqrt(mse) # Calculate RMSE\n",
        "r2 = r2_score(y_test, y_pred) # Calculate R2 score"
      ],
      "metadata": {
        "id": "PROMl-l_H2Sl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rallLRw8H_OD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}