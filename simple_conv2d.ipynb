{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMKJkIJ8OPXzasUEQPC4FiJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cliffochi/aviva_data_science_course/blob/main/simple_conv2d.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###[Problem 1] Creating a 2D convolution layer"
      ],
      "metadata": {
        "id": "NLhzpMInZ9Rq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class Conv1d:\n",
        "    \"\"\"\n",
        "    1D Convolutional layer.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    in_channels : int\n",
        "      Number of input channels.\n",
        "    out_channels : int\n",
        "      Number of output channels.\n",
        "    kernel_size : int\n",
        "      Size of the convolutional kernel.\n",
        "    stride : int, default=1\n",
        "      Stride of the convolution.\n",
        "    padding : int, default=0\n",
        "      Padding added to both sides of the input.\n",
        "    initial_bias : float, default=0.0\n",
        "      Initial value for the bias term.\n",
        "    lr : float, default=0.01\n",
        "      Learning rate for weight and bias updates.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, initial_bias=0.0, lr=0.01):\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.lr = lr\n",
        "        self.W = np.random.randn(out_channels, in_channels, kernel_size)\n",
        "        self.b = np.full(out_channels, initial_bias)\n",
        "        self.dW = np.zeros_like(self.W)\n",
        "        self.db = np.zeros_like(self.b)\n",
        "        self.x = None\n",
        "        self.col = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward propagation of the 1D convolutional layer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : ndarray of shape (n_samples, in_channels, width)\n",
        "          Input to the convolutional layer.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        a : ndarray of shape (n_samples, out_channels, output_width)\n",
        "          Output of the convolutional layer.\n",
        "        \"\"\"\n",
        "        self.x = x\n",
        "        n_samples, in_channels, width = x.shape\n",
        "        output_width = (width + 2 * self.padding - self.kernel_size) // self.stride + 1\n",
        "        a = np.zeros((n_samples, self.out_channels, output_width))\n",
        "\n",
        "        x_padded = np.pad(x, [(0, 0), (0, 0), (self.padding, self.padding)], 'constant')\n",
        "        # Corrected col shape for 1D\n",
        "        self.col = np.zeros((n_samples, in_channels, self.kernel_size, output_width))\n",
        "\n",
        "        for i in range(output_width):\n",
        "            start = i * self.stride\n",
        "            end = start + self.kernel_size\n",
        "            self.col[:, :, :, i] = x_padded[:, :, start:end]\n",
        "\n",
        "        # Reshape col for matrix multiplication: (n_samples * output_width, in_channels * kernel_size)\n",
        "        col_reshaped = self.col.transpose(0, 3, 1, 2).reshape(n_samples * output_width, -1)\n",
        "        col_W = self.W.reshape(self.out_channels, -1).T # (in_channels * kernel_size, out_channels)\n",
        "\n",
        "        # Matrix multiplication: (n_samples * output_width, out_channels)\n",
        "        a = np.dot(col_reshaped, col_W) + self.b\n",
        "        # Reshape back to (n_samples, out_channels, output_width)\n",
        "        a = a.reshape(n_samples, output_width, self.out_channels).transpose(0, 2, 1)\n",
        "\n",
        "        return a\n",
        "\n",
        "    def backward(self, da):\n",
        "        \"\"\"\n",
        "        Backward propagation of the 1D convolutional layer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        da : ndarray of shape (n_samples, out_channels, output_width)\n",
        "          Gradients of the following layer with respect to the output of this layer.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        dx : ndarray of shape (n_samples, in_channels, width)\n",
        "          Gradients of this layer with respect to the input.\n",
        "        \"\"\"\n",
        "        n_samples, out_channels, output_width = da.shape\n",
        "        in_channels = self.in_channels\n",
        "        kernel_size = self.kernel_size\n",
        "        stride = self.stride\n",
        "        padding = self.padding\n",
        "        width = self.x.shape[2]\n",
        "\n",
        "        # Gradient for bias\n",
        "        self.db = np.sum(da, axis=(0, 2))\n",
        "\n",
        "        # Gradient for weights\n",
        "        # Reshape da to (n_samples * output_width, out_channels)\n",
        "        da_reshaped = da.transpose(0, 2, 1).reshape(n_samples * output_width, out_channels)\n",
        "        # Reshape col to (n_samples * output_width, in_channels * kernel_size)\n",
        "        col_reshaped = self.col.transpose(0, 3, 1, 2).reshape(n_samples * output_width, in_channels * kernel_size)\n",
        "\n",
        "        # dW is dot product of col_reshaped.T and da_reshaped\n",
        "        # (in_channels * kernel_size, n_samples * output_width) @ (n_samples * output_width, out_channels)\n",
        "        # Result is (in_channels * kernel_size, out_channels)\n",
        "        # Transpose to get (out_channels, in_channels * kernel_size)\n",
        "        # Reshape to (out_channels, in_channels, kernel_size)\n",
        "        self.dW = np.dot(col_reshaped.T, da_reshaped).T.reshape(out_channels, in_channels, kernel_size)\n",
        "\n",
        "\n",
        "        # Gradient for input\n",
        "        # dcol is dot product of da_reshaped and W_reshaped.T\n",
        "        # W_reshaped is (out_channels, in_channels * kernel_size)\n",
        "        W_reshaped = self.W.reshape(out_channels, in_channels * kernel_size)\n",
        "        # (n_samples * output_width, out_channels) @ (out_channels, in_channels * kernel_size)\n",
        "        # Result is (n_samples * output_width, in_channels * kernel_size)\n",
        "        dcol = np.dot(da_reshaped, W_reshaped).reshape(n_samples, output_width, in_channels, kernel_size).transpose(0, 2, 3, 1) # (n_samples, in_channels, kernel_size, output_width)\n",
        "\n",
        "\n",
        "        # Distribute gradients to input using col2im\n",
        "        dx = np.zeros_like(self.x)\n",
        "        dx_padded_full = np.pad(dx, [(0, 0), (0, 0), (self.padding, self.padding)], 'constant')\n",
        "\n",
        "        for i in range(output_width):\n",
        "            start = i * self.stride\n",
        "            end = start + self.kernel_size\n",
        "            dx_padded_full[:, :, start:end] += dcol[:, :, :, i]\n",
        "\n",
        "        if self.padding > 0:\n",
        "            dx = dx_padded_full[:, :, self.padding:-self.padding]\n",
        "        else:\n",
        "            dx = dx_padded_full\n",
        "\n",
        "        return dx\n",
        "\n",
        "\n",
        "    def update(self):\n",
        "        \"\"\"\n",
        "        Updates the weights and biases of the convolutional layer.\n",
        "        \"\"\"\n",
        "        self.W -= self.lr * self.dW\n",
        "        self.b -= self.lr * self.db\n",
        "\n",
        "class Conv2d(Conv1d):\n",
        "    \"\"\"\n",
        "    2D Convolutional layer, extending Conv1d.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    in_channels : int\n",
        "      Number of input channels.\n",
        "    out_channels : int\n",
        "      Number of output channels.\n",
        "    kernel_size : tuple of int (height, width)\n",
        "      Size of the convolutional kernel.\n",
        "    stride : tuple of int (height_stride, width_stride), default=(1, 1)\n",
        "      Stride of the convolution in height and width.\n",
        "    padding : tuple of int (height_padding, width_padding), default=(0, 0)\n",
        "      Padding added to the height and width of the input.\n",
        "    initial_bias : float, default=0.0\n",
        "      Initial value for the bias term.\n",
        "    lr : float, default=0.01\n",
        "      Learning rate for weight and bias updates.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=(1, 1), padding=(0, 0), initial_bias=0.0, lr=0.01):\n",
        "        if isinstance(kernel_size, int):\n",
        "            kernel_size = (kernel_size, kernel_size)\n",
        "        if isinstance(stride, int):\n",
        "            stride = (stride, stride)\n",
        "        if isinstance(padding, int):\n",
        "            padding = (padding, padding)\n",
        "\n",
        "        # The super().__init__ call here is using 1D logic, which might be\n",
        "        # problematic for a 2D convolution. It's setting self.kernel_size,\n",
        "        # self.stride, and self.padding with values derived from the 2D inputs,\n",
        "        # but these are meant for the Conv1d parent class.\n",
        "        # It's better to initialize Conv2d-specific attributes directly.\n",
        "        # super().__init__(in_channels, out_channels, kernel_size[0] * kernel_size[1], stride[1], padding[1], initial_bias, lr)\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.lr = lr\n",
        "        self.initial_bias = initial_bias # Store for potential re-initialization or inspection\n",
        "\n",
        "        self.kernel_h, self.kernel_w = kernel_size\n",
        "        self.stride_h, self.stride_w = stride\n",
        "        self.padding_h, self.padding_w = padding\n",
        "\n",
        "        # Weights and biases are 2D specific\n",
        "        self.W = np.random.randn(out_channels, in_channels, self.kernel_h, self.kernel_w)\n",
        "        self.b = np.full(out_channels, initial_bias)\n",
        "        self.dW = np.zeros_like(self.W)\n",
        "        self.db = np.zeros_like(self.b)\n",
        "\n",
        "        self.x = None\n",
        "        self.col = None # This will store the result of the im2col operation\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward propagation of the 2D convolutional layer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : ndarray of shape (n_samples, in_channels, height, width)\n",
        "          Input to the convolutional layer (NCHW format).\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        a : ndarray of shape (n_samples, out_channels, output_height, output_width)\n",
        "          Output of the convolutional layer.\n",
        "        \"\"\"\n",
        "        self.x = x\n",
        "        n_samples, in_channels, height, width = x.shape\n",
        "        kernel_h, kernel_w = self.kernel_h, self.kernel_w\n",
        "        stride_h, stride_w = self.stride_h, self.stride_w\n",
        "        padding_h, padding_w = self.padding_h, self.padding_w\n",
        "        out_channels = self.out_channels\n",
        "\n",
        "        output_height = (height + 2 * padding_h - kernel_h) // stride_h + 1\n",
        "        output_width = (width + 2 * padding_w - kernel_w) // stride_w + 1\n",
        "        a = np.zeros((n_samples, out_channels, output_height, output_width))\n",
        "\n",
        "        x_padded = np.pad(x, [(0, 0), (0, 0), (padding_h, padding_h), (padding_w, padding_w)], 'constant')\n",
        "\n",
        "        # Perform im2col\n",
        "        # Output shape of im2col: (n_samples, out_h, out_w, in_c, k_h, k_w)\n",
        "        # Then reshape to (n_samples * out_h * out_w, in_c * k_h * k_w)\n",
        "        self.col = np.zeros((n_samples, output_height, output_width, in_channels, kernel_h, kernel_w))\n",
        "\n",
        "        for h in range(output_height):\n",
        "            for w in range(output_width):\n",
        "                start_h = h * stride_h\n",
        "                end_h = start_h + kernel_h\n",
        "                start_w = w * stride_w\n",
        "                end_w = start_w + kernel_w\n",
        "                self.col[:, h, w, :, :, :] = x_padded[:, :, start_h:end_h, start_w:end_w]\n",
        "\n",
        "        # Reshape col for matrix multiplication\n",
        "        # Shape: (n_samples * output_height * output_width, in_channels * kernel_h * kernel_w)\n",
        "        col_reshaped = self.col.reshape(n_samples * output_height * output_width, -1)\n",
        "\n",
        "        # Reshape W for matrix multiplication\n",
        "        # Shape: (out_channels, in_channels * kernel_h * kernel_w).T\n",
        "        #       = (in_channels * kernel_h * kernel_w, out_channels)\n",
        "        col_W = self.W.reshape(out_channels, -1).T\n",
        "\n",
        "        # Matrix multiplication: (n_samples * output_height * output_width, out_channels)\n",
        "        a_reshaped = np.dot(col_reshaped, col_W) + self.b\n",
        "\n",
        "        # Reshape back to (n_samples, out_channels, output_height, output_width)\n",
        "        a = a_reshaped.reshape(n_samples, output_height, output_width, out_channels).transpose(0, 3, 1, 2)\n",
        "\n",
        "        return a\n",
        "\n",
        "    def backward(self, da):\n",
        "        \"\"\"\n",
        "        Backward propagation of the 2D convolutional layer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        da : ndarray of shape (n_samples, out_channels, output_height, output_width)\n",
        "          Gradients of the following layer with respect to the output of this layer.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        dx : ndarray of shape (n_samples, in_channels, height, width)\n",
        "          Gradients of this layer with respect to the input.\n",
        "        \"\"\"\n",
        "        n_samples, out_channels, output_height, output_width = da.shape\n",
        "        in_channels = self.in_channels\n",
        "        kernel_h, kernel_w = self.kernel_h, self.kernel_w\n",
        "        stride_h, stride_w = self.stride_h, self.stride_w\n",
        "        padding_h, padding_w = self.padding_h, self.padding_w\n",
        "        height, width = self.x.shape[2:]\n",
        "\n",
        "\n",
        "        # Gradient for bias\n",
        "        self.db = np.sum(da, axis=(0, 2, 3))\n",
        "\n",
        "        # Gradient for weights\n",
        "        # Reshape da to (n_samples * output_height * output_width, out_channels)\n",
        "        da_reshaped = da.transpose(0, 2, 3, 1).reshape(n_samples * output_height * output_width, out_channels)\n",
        "\n",
        "        # Reshape col (from forward pass) to (n_samples * output_height * output_width, in_channels * kernel_h * kernel_w)\n",
        "        col_reshaped = self.col.reshape(n_samples * output_height * output_width, -1)\n",
        "\n",
        "        # dW is dot product of col_reshaped.T and da_reshaped\n",
        "        # (in_channels * kernel_h * kernel_w, n_samples * output_height * output_width) @ (n_samples * output_height * output_width, out_channels)\n",
        "        # Result is (in_channels * kernel_h * kernel_w, out_channels)\n",
        "        # Transpose to get (out_channels, in_channels * kernel_h * kernel_w)\n",
        "        # Reshape to (out_channels, in_channels, kernel_h, kernel_w)\n",
        "        self.dW = np.dot(col_reshaped.T, da_reshaped).T.reshape(out_channels, in_channels, kernel_h, kernel_w)\n",
        "\n",
        "\n",
        "        # Gradient for input\n",
        "        # dcol is dot product of da_reshaped and W_reshaped.T\n",
        "        # W_reshaped is (out_channels, in_channels * kernel_h * kernel_w)\n",
        "        W_reshaped = self.W.reshape(out_channels, in_channels * kernel_h * kernel_w)\n",
        "        # (n_samples * output_height * output_width, out_channels) @ (out_channels, in_channels * kernel_h * kernel_w)\n",
        "        # Result is (n_samples * output_height * output_width, in_channels * kernel_h * kernel_w)\n",
        "        dcol_reshaped = np.dot(da_reshaped, W_reshaped)\n",
        "\n",
        "        # Reshape dcol_reshaped back to (n_samples, output_height, output_width, in_channels, kernel_h, kernel_w)\n",
        "        dcol = dcol_reshaped.reshape(n_samples, output_height, output_width, in_channels, kernel_h, kernel_w)\n",
        "\n",
        "\n",
        "        # Distribute gradients to input using col2im\n",
        "        # Initialize dx_padded_full with zeros, matching padded input shape\n",
        "        dx = np.zeros_like(self.x)\n",
        "        padded_height = height + 2 * padding_h\n",
        "        padded_width = width + 2 * padding_w\n",
        "        dx_padded_full = np.zeros((n_samples, in_channels, padded_height, padded_width))\n",
        "\n",
        "        for h in range(output_height):\n",
        "            for w in range(output_width):\n",
        "                start_h = h * stride_h\n",
        "                end_h = start_h + kernel_h\n",
        "                start_w = w * stride_w\n",
        "                end_w = start_w + kernel_w\n",
        "                dx_padded_full[:, :, start_h:end_h, start_w:end_w] += dcol[:, h, w, :, :, :]\n",
        "\n",
        "        if padding_h > 0 or padding_w > 0:\n",
        "            # Remove padding from the result\n",
        "            dx = dx_padded_full[:, :, padding_h:height+padding_h, padding_w:width+padding_w]\n",
        "        else:\n",
        "            dx = dx_padded_full\n",
        "\n",
        "        return dx\n",
        "\n",
        "\n",
        "    def update(self):\n",
        "        \"\"\"\n",
        "        Updates the weights and biases of the convolutional layer.\n",
        "        \"\"\"\n",
        "        self.W -= self.lr * self.dW\n",
        "        self.b -= self.lr * self.db\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Example usage with a dummy MNIST-like input\n",
        "    n_samples = 2\n",
        "    in_channels = 1\n",
        "    height = 28\n",
        "    width = 28\n",
        "    input_data = np.random.randn(n_samples, in_channels, height, width)\n",
        "\n",
        "    # Instantiate a Conv2d layer\n",
        "    conv_layer = Conv2d(in_channels=1, out_channels=3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), lr=0.01)\n",
        "\n",
        "    # Forward pass\n",
        "    output_data = conv_layer.forward(input_data)\n",
        "    print(\"Input shape:\", input_data.shape)\n",
        "    print(\"Output shape:\", output_data.shape)\n",
        "\n",
        "    # Dummy gradients from the next layer\n",
        "    dout = np.random.randn(n_samples, 3, 28, 28)\n",
        "\n",
        "    # Backward pass\n",
        "    din = conv_layer.backward(dout)\n",
        "    print(\"Input gradient shape:\", din.shape)\n",
        "\n",
        "    # Update weights and biases\n",
        "    conv_layer.update()\n",
        "\n",
        "    print(\"\\nTesting with different stride and padding:\")\n",
        "    conv_layer_2 = Conv2d(in_channels=1, out_channels=2, kernel_size=(5, 5), stride=(2, 2), padding=(0, 0), lr=0.01)\n",
        "    output_data_2 = conv_layer_2.forward(input_data)\n",
        "    print(\"Input shape:\", input_data.shape)\n",
        "    print(\"Output shape (stride 2, no padding):\", output_data_2.shape)\n",
        "\n",
        "    # Calculate expected output shape for dout_2\n",
        "    height_2 = 28\n",
        "    width_2 = 28\n",
        "    kernel_h_2, kernel_w_2 = (5, 5)\n",
        "    stride_h_2, stride_w_2 = (2, 2)\n",
        "    padding_h_2, padding_w_2 = (0, 0)\n",
        "    output_height_2 = (height_2 + 2 * padding_h_2 - kernel_h_2) // stride_h_2 + 1\n",
        "    output_width_2 = (width_2 + 2 * padding_w_2 - kernel_w_2) // stride_w_2 + 1\n",
        "    expected_dout_shape_2 = (n_samples, 2, output_height_2, output_width_2)\n",
        "    print(f\"Expected dout_2 shape: {expected_dout_shape_2}\")\n",
        "\n",
        "\n",
        "    dout_2 = np.random.randn(*expected_dout_shape_2) # Use the calculated output shape for dummy gradients\n",
        "    din_2 = conv_layer_2.backward(dout_2)\n",
        "    print(\"Input gradient shape:\", din_2.shape)\n",
        "    conv_layer_2.update()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqE1vvMiZdwE",
        "outputId": "7a5094de-d665-46ed-c412-db35f4bbcf3a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: (2, 1, 28, 28)\n",
            "Output shape: (2, 3, 28, 28)\n",
            "Input gradient shape: (2, 1, 28, 28)\n",
            "\n",
            "Testing with different stride and padding:\n",
            "Input shape: (2, 1, 28, 28)\n",
            "Output shape (stride 2, no padding): (2, 2, 12, 12)\n",
            "Expected dout_2 shape: (2, 2, 12, 12)\n",
            "Input gradient shape: (2, 1, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###[Problem 2] Experiments with 2D convolutional layers on small arrays"
      ],
      "metadata": {
        "id": "w4bWQ1Vabcnv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class Conv2d_Debug:\n",
        "    \"\"\"\n",
        "    2D Convolutional layer for debugging with explicit calculations.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=(1, 1), padding=(0, 0), lr=0.01):\n",
        "        if isinstance(kernel_size, int):\n",
        "            kernel_size = (kernel_size, kernel_size)\n",
        "        if isinstance(stride, int):\n",
        "            stride = (stride, stride)\n",
        "        if isinstance(padding, int):\n",
        "            padding = (padding, padding)\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_h, self.kernel_w = kernel_size\n",
        "        self.stride_h, self.stride_w = stride\n",
        "        self.padding_h, self.padding_w = padding\n",
        "        self.lr = lr\n",
        "        self.W = np.array([[[[ 0.,  0.,  0.],\n",
        "                               [ 0.,  1.,  0.],\n",
        "                               [ 0., -1.,  0.]]],\n",
        "\n",
        "                              [[[ 0.,  0.,  0.],\n",
        "                               [ 0., -1.,  1.],\n",
        "                               [ 0.,  0.,  0.]]]]) # Initialize with the provided weights\n",
        "        self.b = np.zeros(out_channels)\n",
        "        self.dW = np.zeros_like(self.W)\n",
        "        self.db = np.zeros_like(self.b)\n",
        "        self.x = None\n",
        "        self.col = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward propagation of the 2D convolutional layer.\n",
        "        \"\"\"\n",
        "        self.x = x\n",
        "        n_samples, in_channels, height, width = x.shape\n",
        "        out_h = (height + 2 * self.padding_h - self.kernel_h) // self.stride_h + 1\n",
        "        out_w = (width + 2 * self.padding_w - self.kernel_w) // self.stride_w + 1\n",
        "        a = np.zeros((n_samples, self.out_channels, out_h, out_w))\n",
        "        x_padded = np.pad(x, [(0, 0), (0, 0), (self.padding_h, self.padding_h), (self.padding_w, self.padding_w)], 'constant')\n",
        "\n",
        "        # Assuming n_samples is 1 for this debug class based on the provided x\n",
        "        # If n_samples can be > 1, this loop structure needs adjustment\n",
        "        # to iterate over samples as well. For now, focusing on the provided x shape.\n",
        "        for m in range(self.out_channels):\n",
        "            for h in range(out_h):\n",
        "                for w in range(out_w):\n",
        "                    for k in range(self.in_channels):\n",
        "                        for s in range(self.kernel_h):\n",
        "                            for t in range(self.kernel_w):\n",
        "                                i = h * self.stride_h + s\n",
        "                                j = w * self.stride_w + t\n",
        "                                a[0, m, h, w] += x_padded[0, k, i, j] * self.W[m, k, s, t]\n",
        "                    a[0, m, h, w] += self.b[m]\n",
        "        return a\n",
        "\n",
        "    def backward(self, da):\n",
        "        \"\"\"\n",
        "        Backward propagation of the 2D convolutional layer.\n",
        "        \"\"\"\n",
        "        # Expected da shape is (n_samples, out_channels, out_h, out_w)\n",
        "        n_samples, out_channels, out_h, out_w = da.shape\n",
        "        in_channels, in_h, in_w = self.x.shape[1:]\n",
        "\n",
        "        self.dW = np.zeros_like(self.W)\n",
        "        self.db = np.sum(da, axis=(0, 2, 3))\n",
        "        dx = np.zeros_like(self.x)\n",
        "        x_padded = np.pad(self.x, [(0, 0), (0, 0), (self.padding_h, self.padding_h), (self.padding_w, self.padding_w)], 'constant')\n",
        "        dx_padded = np.pad(dx, [(0, 0), (0, 0), (self.padding_h, self.padding_h), (self.padding_w, self.padding_w)], 'constant')\n",
        "\n",
        "        # Assuming n_samples is 1 for this debug class based on the provided x and delta shape fix\n",
        "        for m in range(out_channels):\n",
        "            for k in range(in_channels):\n",
        "                for s in range(self.kernel_h):\n",
        "                    for t in range(self.kernel_w):\n",
        "                        for h in range(out_h):\n",
        "                            for w in range(out_w):\n",
        "                                i = h * self.stride_h + s\n",
        "                                j = w * self.stride_w + t\n",
        "                                self.dW[m, k, s, t] += da[0, m, h, w] * x_padded[0, k, i, j]\n",
        "\n",
        "        for m in range(out_channels):\n",
        "            for k in range(in_channels):\n",
        "                for s in range(self.kernel_h):\n",
        "                    for t in range(self.kernel_w):\n",
        "                        for h in range(out_h):\n",
        "                            for w in range(out_w):\n",
        "                                di = h * self.stride_h + s\n",
        "                                dj = w * self.stride_w + t\n",
        "                                if (0 <= di < dx_padded.shape[2]) and (0 <= dj < dx_padded.shape[3]):\n",
        "                                    dx_padded[0, k, di, dj] += da[0, m, h, w] * self.W[m, k, s, t]\n",
        "\n",
        "        if self.padding_h > 0 or self.padding_w > 0:\n",
        "            dx = dx_padded[:, :, self.padding_h:-self.padding_h, self.padding_w:-self.padding_w]\n",
        "        else:\n",
        "            dx = dx_padded\n",
        "\n",
        "        return dx, self.dW, self.db\n",
        "\n",
        "# Input x and weights w\n",
        "x = np.array([[[[ 1,  2,  3,  4],\n",
        "                [ 5,  6,  7,  8],\n",
        "                [ 9, 10, 11, 12],\n",
        "                [13, 14, 15, 16]]]])\n",
        "\n",
        "w_provided = np.array([[[[ 0.,  0.,  0.],\n",
        "                           [ 0.,  1.,  0.],\n",
        "                           [ 0., -1.,  0.]]],\n",
        "\n",
        "                         [[[ 0.,  0.,  0.],\n",
        "                           [ 0., -1.,  1.],\n",
        "                           [ 0.,  0.,  0.]]]])\n",
        "\n",
        "# Instantiate the Conv2d_Debug layer with the provided weights\n",
        "conv_debug = Conv2d_Debug(in_channels=1, out_channels=2, kernel_size=(3, 3), stride=(1, 1), padding=(0, 0))\n",
        "conv_debug.W = w_provided\n",
        "conv_debug.b = np.zeros(2) # Initialize bias to zero as not specified\n",
        "\n",
        "# Forward propagation\n",
        "output_forward = conv_debug.forward(x)\n",
        "print(\"Forward Propagation Output:\")\n",
        "print(output_forward)\n",
        "\n",
        "# Error delta - Corrected shape to match the expected output shape of the layer\n",
        "# The layer processes input x with shape (1, 1, 4, 4).\n",
        "# With kernel (3, 3), stride (1, 1), padding (0, 0), output shape is (1, 2, 2, 2).\n",
        "# The gradient delta should have the same shape as the output.\n",
        "delta = np.array([[[ -4,  -4],\n",
        "                   [ 10,  11]]]) # Changed to (1, 2, 2) - Still not right based on the error,\n",
        "                                  # The expected shape is (1, out_channels, out_h, out_w)\n",
        "\n",
        "# Re-calculating the expected output shape for Conv2d_Debug with x (1, 1, 4, 4), kernel (3, 3), stride (1, 1), padding (0, 0)\n",
        "n_samples_x, in_channels_x, height_x, width_x = x.shape\n",
        "kernel_h_debug, kernel_w_debug = conv_debug.kernel_h, conv_debug.kernel_w\n",
        "stride_h_debug, stride_w_debug = conv_debug.stride_h, conv_debug.stride_w\n",
        "padding_h_debug, padding_w_debug = conv_debug.padding_h, conv_debug.padding_w\n",
        "out_channels_debug = conv_debug.out_channels\n",
        "\n",
        "output_height_debug = (height_x + 2 * padding_h_debug - kernel_h_debug) // stride_h_debug + 1\n",
        "output_width_debug = (width_x + 2 * padding_w_debug - kernel_w_debug) // stride_w_debug + 1\n",
        "\n",
        "# The correct shape for delta should be (n_samples, out_channels, output_height, output_width)\n",
        "# With x having n_samples=1, out_channels=2, output_height=2, output_width=2\n",
        "# The correct shape for delta is (1, 2, 2, 2)\n",
        "delta = np.array([[[[ -4,  -4],\n",
        "                    [ 10,  11]]],\n",
        "\n",
        "                  [[[  1,  -7],\n",
        "                    [  1, -11]]]])\n",
        "# The above delta shape is (2, 2, 2, 2), which implies n_samples=2.\n",
        "# Given x has n_samples=1, delta should have n_samples=1.\n",
        "# Let's correct delta to have shape (1, 2, 2, 2)\n",
        "\n",
        "delta = np.array([[[[ -4.,  -4.],\n",
        "                    [ 10.,  11.]],\n",
        "\n",
        "                   [[  1.,  -7.],\n",
        "                    [  1., -11.]]]])\n",
        "# This delta has shape (1, 2, 2, 2). Let's use this.\n",
        "\n",
        "\n",
        "# Backward propagation\n",
        "dx_backward, dW_backward, db_backward = conv_debug.backward(delta)\n",
        "print(\"\\nBackward Propagation Gradients:\")\n",
        "print(\"Gradient w.r.t. input (dx):\")\n",
        "print(dx_backward)\n",
        "print(\"Gradient w.r.t. weights (dW):\")\n",
        "print(dW_backward)\n",
        "print(\"Gradient w.r.t. bias (db):\")\n",
        "print(db_backward)\n",
        "\n",
        "# Experiment with padding (Problem 2 - With padding)\n",
        "conv_padded = Conv2d_Debug(in_channels=1, out_channels=2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "conv_padded.W = w_provided\n",
        "conv_padded.b = np.zeros(2)\n",
        "output_forward_padded = conv_padded.forward(x)\n",
        "print(\"\\nForward Propagation Output (with padding=1):\")\n",
        "print(output_forward_padded)\n",
        "\n",
        "# Calculate expected output shape for delta_padded with padding=1\n",
        "height_x_padded = height_x + 2 * conv_padded.padding_h\n",
        "width_x_padded = width_x + 2 * conv_padded.padding_w\n",
        "output_height_padded = (height_x + 2 * conv_padded.padding_h - conv_padded.kernel_h) // conv_padded.stride_h + 1\n",
        "output_width_padded = (width_x + 2 * conv_padded.padding_w - conv_padded.kernel_w) // conv_padded.stride_w + 1\n",
        "# Expected delta_padded shape is (n_samples=1, out_channels=2, output_height=4, output_width=4)\n",
        "\n",
        "delta_padded = np.array([[[[ -4.,  -4.,  0.,  0.], # Output size with padding is (1, 2, 4, 4)\n",
        "                            [ 10.,  11.,  0.,  0.],\n",
        "                            [  0.,   0.,  0.,  0.],\n",
        "                            [  0.,   0.,  0.,  0.]],\n",
        "\n",
        "                           [[  1.,  -7.,  0.,  0.],\n",
        "                            [  1., -11.,  0.,  0.],\n",
        "                            [  0.,   0.,  0.,  0.],\n",
        "                            [  0.,   0.,  0.,  0.]]]]) # Corrected shape to (1, 2, 4, 4)\n",
        "\n",
        "\n",
        "dx_backward_padded, dW_backward_padded, db_backward_padded = conv_padded.backward(delta_padded)\n",
        "print(\"\\nBackward Propagation Gradients (with padding=1):\")\n",
        "print(\"Gradient w.r.t. input (dx_padded):\")\n",
        "print(dx_backward_padded)\n",
        "print(\"Gradient w.r.t. weights (dW_backward_padded):\")\n",
        "print(dW_backward_padded)\n",
        "print(\"Gradient w.r.t. bias (db_backward_padded):\")\n",
        "print(db_backward_padded)\n",
        "\n",
        "# Manual Calculation Check for Forward Propagation (without padding)\n",
        "print(\"\\nManual Calculation Check (Forward - No Padding):\")\n",
        "output_manual = np.zeros((1, 2, 2, 2))\n",
        "for m in range(2): # output channels\n",
        "    for h_out in range(2): # output height\n",
        "        for w_out in range(2): # output width\n",
        "            for k_in in range(1): # input channels\n",
        "                for s in range(3): # kernel height\n",
        "                    for t in range(3): # kernel width\n",
        "                        h_in = h_out * 1 + s\n",
        "                        w_in = w_out * 1 + t\n",
        "                        if 0 <= h_in < 4 and 0 <= w_in < 4:\n",
        "                            output_manual[0, m, h_out, w_out] += x[0, k_in, h_in, w_in] * w_provided[m, k_in, s, t]\n",
        "            output_manual[0, m, h_out, w_out] += 0 # bias is 0\n",
        "\n",
        "print(output_manual)\n",
        "\n",
        "# Manual Calculation Check for Backward Propagation (without padding) - Gradient w.r.t. weights\n",
        "print(\"\\nManual Calculation Check (Backward - dW - No Padding):\")\n",
        "dW_manual = np.zeros_like(w_provided)\n",
        "# The delta shape should match the output shape of the forward pass.\n",
        "# For the non-padded case, output shape is (1, 2, 2, 2).\n",
        "# So, delta should be (1, 2, 2, 2).\n",
        "# Let's use the corrected delta for the manual check as well.\n",
        "# delta = np.array([[[[ -4.,  -4.], [ 10.,  11.]], [[  1.,  -7.], [  1., -11.]]]]) # Corrected delta shape (1, 2, 2, 2)\n",
        "\n",
        "for m in range(2): # output channels\n",
        "    for k in range(1): # input channels\n",
        "        for s in range(3): # kernel height\n",
        "            for t in range(3): # kernel width\n",
        "                for h_out in range(2): # output height\n",
        "                    for w_out in range(2): # output width\n",
        "                        h_in = h_out * 1 + s\n",
        "                        w_in = w_out * 1 + t\n",
        "                        # Ensure input indices are within bounds\n",
        "                        if 0 <= h_in < x.shape[2] and 0 <= w_in < x.shape[3]:\n",
        "                             dW_manual[m, k, s, t] += delta[0, m, h_out, w_out] * x[0, k, h_in, w_in] # Use delta[0] because n_samples is 1\n",
        "print(dW_manual)\n",
        "\n",
        "# Manual Calculation Check for Backward Propagation (without padding) - Gradient w.r.t. input\n",
        "print(\"\\nManual Calculation Check (Backward - dx - No Padding):\")\n",
        "dx_manual = np.zeros_like(x)\n",
        "# Use the corrected delta shape (1, 2, 2, 2)\n",
        "# delta = np.array([[[[ -4.,  -4.], [ 10.,  11.]], [[  1.,  -7.], [  1., -11.]]]]) # Corrected delta shape (1, 2, 2, 2)\n",
        "\n",
        "for k_in in range(1): # input channels\n",
        "    for h_in in range(4): # input height\n",
        "        for w_in in range(4): # input width\n",
        "            for m_out in range(2): # output channels\n",
        "                for s in range(3): # kernel height\n",
        "                    for t in range(3): # kernel width\n",
        "                        h_out = h_in - s\n",
        "                        w_out = w_in - t\n",
        "                        # Ensure output indices are within bounds\n",
        "                        if 0 <= h_out < 2 and 0 <= w_out < 2:\n",
        "                             dx_manual[0, k_in, h_in, w_in] += delta[0, m_out, h_out, w_out] * w_provided[m_out, k_in, s, t] # Use delta[0] because n_samples is 1\n",
        "\n",
        "print(dx_manual)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nt1vZYifacso",
        "outputId": "564eb643-23a0-44af-880e-16fed18e6214"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forward Propagation Output:\n",
            "[[[[-4. -4.]\n",
            "   [-4. -4.]]\n",
            "\n",
            "  [[ 1.  1.]\n",
            "   [ 1.  1.]]]]\n",
            "\n",
            "Backward Propagation Gradients:\n",
            "Gradient w.r.t. input (dx):\n",
            "[[[[  0   0   0   0]\n",
            "   [  0  -5   4  -7]\n",
            "   [  0  13  27 -11]\n",
            "   [  0 -10 -11   0]]]]\n",
            "Gradient w.r.t. weights (dW):\n",
            "[[[[ 104.  117.  130.]\n",
            "   [ 156.  169.  182.]\n",
            "   [ 208.  221.  234.]]]\n",
            "\n",
            "\n",
            " [[[ -74.  -90. -106.]\n",
            "   [-138. -154. -170.]\n",
            "   [-202. -218. -234.]]]]\n",
            "Gradient w.r.t. bias (db):\n",
            "[ 13. -16.]\n",
            "\n",
            "Forward Propagation Output (with padding=1):\n",
            "[[[[ -4.  -4.  -4.  -4.]\n",
            "   [ -4.  -4.  -4.  -4.]\n",
            "   [ -4.  -4.  -4.  -4.]\n",
            "   [ 13.  14.  15.  16.]]\n",
            "\n",
            "  [[  1.   1.   1.  -4.]\n",
            "   [  1.   1.   1.  -8.]\n",
            "   [  1.   1.   1. -12.]\n",
            "   [  1.   1.   1. -16.]]]]\n",
            "\n",
            "Backward Propagation Gradients (with padding=1):\n",
            "Gradient w.r.t. input (dx_padded):\n",
            "[[[[ -5   4  -7   0]\n",
            "   [ 13  27 -11   0]\n",
            "   [-10 -11   0   0]\n",
            "   [  0   0   0   0]]]]\n",
            "Gradient w.r.t. weights (dW_backward_padded):\n",
            "[[[[  11.   32.   53.]\n",
            "   [  51.  104.  117.]\n",
            "   [  79.  156.  169.]]]\n",
            "\n",
            "\n",
            " [[[ -11.  -21.  -31.]\n",
            "   [ -62.  -74.  -90.]\n",
            "   [-134. -138. -154.]]]]\n",
            "Gradient w.r.t. bias (db_backward_padded):\n",
            "[ 13. -16.]\n",
            "\n",
            "Manual Calculation Check (Forward - No Padding):\n",
            "[[[[-4. -4.]\n",
            "   [-4. -4.]]\n",
            "\n",
            "  [[ 1.  1.]\n",
            "   [ 1.  1.]]]]\n",
            "\n",
            "Manual Calculation Check (Backward - dW - No Padding):\n",
            "[[[[ 104.  117.  130.]\n",
            "   [ 156.  169.  182.]\n",
            "   [ 208.  221.  234.]]]\n",
            "\n",
            "\n",
            " [[[ -74.  -90. -106.]\n",
            "   [-138. -154. -170.]\n",
            "   [-202. -218. -234.]]]]\n",
            "\n",
            "Manual Calculation Check (Backward - dx - No Padding):\n",
            "[[[[  0   0   0   0]\n",
            "   [  0  -5   4  -7]\n",
            "   [  0  13  27 -11]\n",
            "   [  0 -10 -11   0]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###[Problem 3] Output size after 2D convolution"
      ],
      "metadata": {
        "id": "BysypxyQDu7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_2d_convolution_output_size(input_height, input_width, padding_height, padding_width, filter_height, filter_width, stride_height, stride_width):\n",
        "    \"\"\"\n",
        "    Calculates the output size (height and width) after a 2D convolution.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    input_height : int\n",
        "        Height of the input feature map.\n",
        "    input_width : int\n",
        "        Width of the input feature map.\n",
        "    padding_height : int\n",
        "        Padding applied to the height of the input.\n",
        "    padding_width : int\n",
        "        Padding applied to the width of the input.\n",
        "    filter_height : int\n",
        "        Height of the convolutional filter.\n",
        "    filter_width : int\n",
        "        Width of the convolutional filter.\n",
        "    stride_height : int\n",
        "        Stride of the convolution in the height direction.\n",
        "    stride_width : int\n",
        "        Stride of the convolution in the width direction.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    output_height : int\n",
        "        Height of the output feature map.\n",
        "    output_width : int\n",
        "        Width of the output feature map.\n",
        "    \"\"\"\n",
        "    output_height = (input_height + 2 * padding_height - filter_height) // stride_height + 1\n",
        "    output_width = (input_width + 2 * padding_width - filter_width) // stride_width + 1\n",
        "    return output_height, output_width\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Example usage:\n",
        "    input_h = 28\n",
        "    input_w = 28\n",
        "    pad_h = 1\n",
        "    pad_w = 1\n",
        "    filter_h = 3\n",
        "    filter_w = 3\n",
        "    stride_h = 1\n",
        "    stride_w = 1\n",
        "\n",
        "    out_h, out_w = calculate_2d_convolution_output_size(input_h, input_w, pad_h, pad_w, filter_h, filter_w, stride_h, stride_w)\n",
        "    print(f\"Input height: {input_h}, width: {input_w}\")\n",
        "    print(f\"Padding height: {pad_h}, width: {pad_w}\")\n",
        "    print(f\"Filter height: {filter_h}, width: {filter_w}\")\n",
        "    print(f\"Stride height: {stride_h}, width: {stride_w}\")\n",
        "    print(f\"Output height: {out_h}, width: {out_w}\")\n",
        "\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    input_h = 10\n",
        "    input_w = 10\n",
        "    pad_h = 0\n",
        "    pad_w = 0\n",
        "    filter_h = 2\n",
        "    filter_w = 2\n",
        "    stride_h = 2\n",
        "    stride_w = 2\n",
        "\n",
        "    out_h, out_w = calculate_2d_convolution_output_size(input_h, input_w, pad_h, pad_w, filter_h, filter_w, stride_h, stride_w)\n",
        "    print(f\"Input height: {input_h}, width: {input_w}\")\n",
        "    print(f\"Padding height: {pad_h}, width: {pad_w}\")\n",
        "    print(f\"Filter height: {filter_h}, width: {filter_w}\")\n",
        "    print(f\"Stride height: {stride_h}, width: {stride_w}\")\n",
        "    print(f\"Output height: {out_h}, width: {out_w}\")"
      ],
      "metadata": {
        "id": "PVWdo89tbJQD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63c866ef-32b0-4816-d232-a5003d8c03f2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input height: 28, width: 28\n",
            "Padding height: 1, width: 1\n",
            "Filter height: 3, width: 3\n",
            "Stride height: 1, width: 1\n",
            "Output height: 28, width: 28\n",
            "------------------------------\n",
            "Input height: 10, width: 10\n",
            "Padding height: 0, width: 0\n",
            "Filter height: 2, width: 2\n",
            "Stride height: 2, width: 2\n",
            "Output height: 5, width: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "\n",
        "1.  **Function Definition:**\n",
        "\n",
        "      * The code defines a function `calculate_2d_convolution_output_size` that takes the input height, input width, padding in both height and width directions, filter size (height and width), and stride in both height and width directions as input.\n",
        "\n",
        "2.  **Output Size Calculation:**\n",
        "\n",
        "      * It directly implements the provided formulas for calculating the output height (`Nh,out`) and output width (`Nw,out`).\n",
        "      * Integer division (`//`) is used to ensure that the output dimensions are integers.\n",
        "\n",
        "3.  **Return Values:**\n",
        "\n",
        "      * The function returns the calculated `output_height` and `output_width` as a tuple.\n",
        "\n",
        "4.  **Example Usage:**\n",
        "\n",
        "      * The `if __name__ == '__main__':` block demonstrates how to use the function with sample input values. It prints the input parameters and the resulting output height and width. Two different sets of parameters are used to show different output size calculations."
      ],
      "metadata": {
        "id": "ayHWDgCmEd9M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###[Problem 4] Creating a max pooling layer"
      ],
      "metadata": {
        "id": "j6tn0TrxEsPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class MaxPool2D:\n",
        "    \"\"\"\n",
        "    2D Max Pooling layer.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    pool_size : tuple of int (height, width)\n",
        "        Size of the pooling window.\n",
        "    stride : tuple of int (height_stride, width_stride), default=None\n",
        "        Stride of the pooling operation. If None, it defaults to pool_size.\n",
        "    \"\"\"\n",
        "    def __init__(self, pool_size, stride=None):\n",
        "        self.pool_h, self.pool_w = pool_size\n",
        "        if stride is None:\n",
        "            self.stride_h, self.stride_w = self.pool_h, self.pool_w\n",
        "        else:\n",
        "            self.stride_h, self.stride_w = stride\n",
        "        self.x = None\n",
        "        self.arg_max = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward propagation of the 2D max pooling layer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : ndarray of shape (n_samples, n_channels, height, width)\n",
        "            Input to the pooling layer.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        a : ndarray of shape (n_samples, n_channels, output_height, output_width)\n",
        "            Output of the pooling layer.\n",
        "        \"\"\"\n",
        "        self.x = x\n",
        "        n_samples, n_channels, height, width = x.shape\n",
        "        output_height = (height - self.pool_h) // self.stride_h + 1\n",
        "        output_width = (width - self.pool_w) // self.stride_w + 1\n",
        "        a = np.zeros((n_samples, n_channels, output_height, output_width))\n",
        "        self.arg_max = np.zeros_like(a, dtype=int)  # Store the index of the maximum value\n",
        "\n",
        "        for i in range(output_height):\n",
        "            for j in range(output_width):\n",
        "                h_start = i * self.stride_h\n",
        "                h_end = h_start + self.pool_h\n",
        "                w_start = j * self.stride_w\n",
        "                w_end = w_start + self.pool_w\n",
        "\n",
        "                pool_region = x[:, :, h_start:h_end, w_start:w_end]\n",
        "                a[:, :, i, j] = np.max(pool_region, axis=(2, 3))\n",
        "\n",
        "                # Store the index of the maximum value within the pooling region\n",
        "                arg_max_local = np.argmax(pool_region.reshape(n_samples, n_channels, -1), axis=2)\n",
        "                self.arg_max[:, :, i, j] = arg_max_local\n",
        "\n",
        "        return a\n",
        "\n",
        "    def backward(self, da):\n",
        "        \"\"\"\n",
        "        Backward propagation of the 2D max pooling layer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        da : ndarray of shape (n_samples, n_channels, output_height, output_width)\n",
        "            Gradients of the following layer with respect to the output of this layer.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        dx : ndarray of shape (n_samples, n_channels, height, width)\n",
        "            Gradients of this layer with respect to the input.\n",
        "        \"\"\"\n",
        "        dx = np.zeros_like(self.x, dtype=np.float64)  # Initialize dx as float\n",
        "        n_samples, n_channels, height, width = self.x.shape\n",
        "        output_height, output_width = da.shape[2:]\n",
        "\n",
        "        for i in range(output_height):\n",
        "            for j in range(output_width):\n",
        "                h_start = i * self.stride_h\n",
        "                h_end = h_start + self.pool_h\n",
        "                w_start = j * self.stride_w\n",
        "                w_end = w_start + self.pool_w\n",
        "\n",
        "                # Create a mask to pass the gradient only to the max element\n",
        "                mask = np.zeros((n_samples, n_channels, self.pool_h, self.pool_w))\n",
        "                arg_max_local = self.arg_max[:, :, i, j]  # Get the stored index\n",
        "\n",
        "                # Convert the flat index to 2D indices within the pooling region\n",
        "                row_index = arg_max_local // self.pool_w\n",
        "                col_index = arg_max_local % self.pool_w\n",
        "\n",
        "                for ns in range(n_samples):\n",
        "                    for nc in range(n_channels):\n",
        "                        mask[ns, nc, row_index[ns, nc], col_index[ns, nc]] = 1\n",
        "\n",
        "                # Distribute the gradient to the corresponding position in the input gradient\n",
        "                dx[:, :, h_start:h_end, w_start:w_end] += da[:, :, i, j][:, :, np.newaxis, np.newaxis] * mask\n",
        "\n",
        "        return dx\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Example usage:\n",
        "    x = np.array([[[[1, 2, 3, 4],\n",
        "                    [5, 6, 7, 8],\n",
        "                    [9, 10, 11, 12],\n",
        "                    [13, 14, 15, 16]]]])\n",
        "    print(\"Input:\\n\", x)\n",
        "    pool_layer = MaxPool2D(pool_size=(2, 2), stride=(2, 2))\n",
        "    output = pool_layer.forward(x)\n",
        "    print(\"MaxPool Output:\\n\", output)\n",
        "\n",
        "    dout = np.array([[[[6, 8],\n",
        "                       [14, 16]]]])\n",
        "    din = pool_layer.backward(dout)\n",
        "    print(\"MaxPool Input Gradient:\\n\", din)\n",
        "\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    x_multi_channel = np.array([[[[1, 2, 3, 4],\n",
        "                                   [5, 6, 7, 8],\n",
        "                                   [9, 10, 11, 12],\n",
        "                                   [13, 14, 15, 16]],\n",
        "\n",
        "                                  [[17, 18, 19, 20],\n",
        "                                   [21, 22, 23, 24],\n",
        "                                   [25, 26, 27, 28],\n",
        "                                   [29, 30, 31, 32]]]])\n",
        "    print(\"Multi-channel Input:\\n\", x_multi_channel)\n",
        "    pool_layer_multi = MaxPool2D(pool_size=(2, 2), stride=(2, 2))\n",
        "    output_multi = pool_layer_multi.forward(x_multi_channel)\n",
        "    print(\"Multi-channel MaxPool Output:\\n\", output_multi)\n",
        "\n",
        "    dout_multi = np.array([[[[3, 4],\n",
        "                                [7, 8]],\n",
        "\n",
        "                               [[11, 12],\n",
        "                                [15, 16]]]])\n",
        "    din_multi = pool_layer_multi.backward(dout_multi)\n",
        "    print(\"Multi-channel MaxPool Input Gradient:\\n\", din_multi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFJV8-2fEcXL",
        "outputId": "130afa92-e41a-4094-e6ee-439960d0d162"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            " [[[[ 1  2  3  4]\n",
            "   [ 5  6  7  8]\n",
            "   [ 9 10 11 12]\n",
            "   [13 14 15 16]]]]\n",
            "MaxPool Output:\n",
            " [[[[ 6.  8.]\n",
            "   [14. 16.]]]]\n",
            "MaxPool Input Gradient:\n",
            " [[[[ 0.  0.  0.  0.]\n",
            "   [ 0.  6.  0.  8.]\n",
            "   [ 0.  0.  0.  0.]\n",
            "   [ 0. 14.  0. 16.]]]]\n",
            "------------------------------\n",
            "Multi-channel Input:\n",
            " [[[[ 1  2  3  4]\n",
            "   [ 5  6  7  8]\n",
            "   [ 9 10 11 12]\n",
            "   [13 14 15 16]]\n",
            "\n",
            "  [[17 18 19 20]\n",
            "   [21 22 23 24]\n",
            "   [25 26 27 28]\n",
            "   [29 30 31 32]]]]\n",
            "Multi-channel MaxPool Output:\n",
            " [[[[ 6.  8.]\n",
            "   [14. 16.]]\n",
            "\n",
            "  [[22. 24.]\n",
            "   [30. 32.]]]]\n",
            "Multi-channel MaxPool Input Gradient:\n",
            " [[[[ 0.  0.  0.  0.]\n",
            "   [ 0.  3.  0.  4.]\n",
            "   [ 0.  0.  0.  0.]\n",
            "   [ 0.  7.  0.  8.]]\n",
            "\n",
            "  [[ 0.  0.  0.  0.]\n",
            "   [ 0. 11.  0. 12.]\n",
            "   [ 0.  0.  0.  0.]\n",
            "   [ 0. 15.  0. 16.]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###[Problem 5] (Advanced assignment) Creating average pooling"
      ],
      "metadata": {
        "id": "A3OXXagbGC1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class AveragePool2D:\n",
        "    \"\"\"\n",
        "    2D Average Pooling layer.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    pool_size : tuple of int (height, width)\n",
        "        Size of the pooling window.\n",
        "    stride : tuple of int (height_stride, width_stride), default=None\n",
        "        Stride of the pooling operation. If None, it defaults to pool_size.\n",
        "    \"\"\"\n",
        "    def __init__(self, pool_size, stride=None):\n",
        "        self.pool_h, self.pool_w = pool_size\n",
        "        if stride is None:\n",
        "            self.stride_h, self.stride_w = self.pool_h, self.pool_w\n",
        "        else:\n",
        "            self.stride_h, self.stride_w = stride\n",
        "        self.x = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward propagation of the 2D average pooling layer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : ndarray of shape (n_samples, n_channels, height, width)\n",
        "            Input to the pooling layer.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        a : ndarray of shape (n_samples, n_channels, output_height, output_width)\n",
        "            Output of the pooling layer.\n",
        "        \"\"\"\n",
        "        self.x = x\n",
        "        n_samples, n_channels, height, width = x.shape\n",
        "        output_height = (height - self.pool_h) // self.stride_h + 1\n",
        "        output_width = (width - self.pool_w) // self.stride_w + 1\n",
        "        a = np.zeros((n_samples, n_channels, output_height, output_width))\n",
        "\n",
        "        for i in range(output_height):\n",
        "            for j in range(output_width):\n",
        "                h_start = i * self.stride_h\n",
        "                h_end = h_start + self.pool_h\n",
        "                w_start = j * self.stride_w\n",
        "                w_end = w_start + self.pool_w\n",
        "\n",
        "                pool_region = x[:, :, h_start:h_end, w_start:w_end]\n",
        "                a[:, :, i, j] = np.mean(pool_region, axis=(2, 3))\n",
        "\n",
        "        return a\n",
        "\n",
        "    def backward(self, da):\n",
        "        \"\"\"\n",
        "        Backward propagation of the 2D average pooling layer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        da : ndarray of shape (n_samples, n_channels, output_height, output_width)\n",
        "            Gradients of the following layer with respect to the output of this layer.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        dx : ndarray of shape (n_samples, n_channels, height, width)\n",
        "            Gradients of this layer with respect to the input.\n",
        "        \"\"\"\n",
        "        dx = np.zeros_like(self.x, dtype=np.float64)\n",
        "        n_samples, n_channels, height, width = self.x.shape\n",
        "        output_height, output_width = da.shape[2:]\n",
        "\n",
        "        # Gradient for each element in the pooling region is the output gradient\n",
        "        # divided by the number of elements in the pooling region.\n",
        "        scale = 1.0 / (self.pool_h * self.pool_w)\n",
        "\n",
        "        for i in range(output_height):\n",
        "            for j in range(output_width):\n",
        "                h_start = i * self.stride_h\n",
        "                h_end = h_start + self.pool_h\n",
        "                w_start = j * self.stride_w\n",
        "                w_end = w_start + self.pool_w\n",
        "\n",
        "                # Distribute the gradient equally to all elements in the pooling region\n",
        "                gradient = da[:, :, i, j][:, :, np.newaxis, np.newaxis] * scale\n",
        "                dx[:, :, h_start:h_end, w_start:w_end] += gradient\n",
        "\n",
        "        return dx\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Example usage:\n",
        "    x = np.array([[[[1, 2, 3, 4],\n",
        "                    [5, 6, 7, 8],\n",
        "                    [9, 10, 11, 12],\n",
        "                    [13, 14, 15, 16]]]])\n",
        "    print(\"Input:\\n\", x)\n",
        "    pool_layer = AveragePool2D(pool_size=(2, 2), stride=(2, 2))\n",
        "    output = pool_layer.forward(x)\n",
        "    print(\"AveragePool Output:\\n\", output)\n",
        "\n",
        "    dout = np.array([[[[6, 8],\n",
        "                       [14, 16]]]])\n",
        "    din = pool_layer.backward(dout)\n",
        "    print(\"AveragePool Input Gradient:\\n\", din)\n",
        "\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    x_multi_channel = np.array([[[[1, 2, 3, 4],\n",
        "                                   [5, 6, 7, 8],\n",
        "                                   [9, 10, 11, 12],\n",
        "                                   [13, 14, 15, 16]],\n",
        "\n",
        "                                  [[17, 18, 19, 20],\n",
        "                                   [21, 22, 23, 24],\n",
        "                                   [25, 26, 27, 28],\n",
        "                                   [29, 30, 31, 32]]]])\n",
        "    print(\"Multi-channel Input:\\n\", x_multi_channel)\n",
        "    pool_layer_multi = AveragePool2D(pool_size=(2, 2), stride=(2, 2))\n",
        "    output_multi = pool_layer_multi.forward(x_multi_channel)\n",
        "    print(\"Multi-channel AveragePool Output:\\n\", output_multi)\n",
        "\n",
        "    dout_multi = np.array([[[[3, 4],\n",
        "                                [7, 8]],\n",
        "\n",
        "                               [[11, 12],\n",
        "                                [15, 16]]]])\n",
        "    din_multi = pool_layer_multi.backward(dout_multi)\n",
        "    print(\"Multi-channel AveragePool Input Gradient:\\n\", din_multi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgB38_jmE8pp",
        "outputId": "d9e56421-93e3-421f-fc5b-4212eb438a4d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            " [[[[ 1  2  3  4]\n",
            "   [ 5  6  7  8]\n",
            "   [ 9 10 11 12]\n",
            "   [13 14 15 16]]]]\n",
            "AveragePool Output:\n",
            " [[[[ 3.5  5.5]\n",
            "   [11.5 13.5]]]]\n",
            "AveragePool Input Gradient:\n",
            " [[[[1.5 1.5 2.  2. ]\n",
            "   [1.5 1.5 2.  2. ]\n",
            "   [3.5 3.5 4.  4. ]\n",
            "   [3.5 3.5 4.  4. ]]]]\n",
            "------------------------------\n",
            "Multi-channel Input:\n",
            " [[[[ 1  2  3  4]\n",
            "   [ 5  6  7  8]\n",
            "   [ 9 10 11 12]\n",
            "   [13 14 15 16]]\n",
            "\n",
            "  [[17 18 19 20]\n",
            "   [21 22 23 24]\n",
            "   [25 26 27 28]\n",
            "   [29 30 31 32]]]]\n",
            "Multi-channel AveragePool Output:\n",
            " [[[[ 3.5  5.5]\n",
            "   [11.5 13.5]]\n",
            "\n",
            "  [[19.5 21.5]\n",
            "   [27.5 29.5]]]]\n",
            "Multi-channel AveragePool Input Gradient:\n",
            " [[[[0.75 0.75 1.   1.  ]\n",
            "   [0.75 0.75 1.   1.  ]\n",
            "   [1.75 1.75 2.   2.  ]\n",
            "   [1.75 1.75 2.   2.  ]]\n",
            "\n",
            "  [[2.75 2.75 3.   3.  ]\n",
            "   [2.75 2.75 3.   3.  ]\n",
            "   [3.75 3.75 4.   4.  ]\n",
            "   [3.75 3.75 4.   4.  ]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###[Problem 6] Smoothing"
      ],
      "metadata": {
        "id": "R1aVt4C-GZ9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class Flatten:\n",
        "    \"\"\"\n",
        "    Flattens the input tensor from (n_samples, n_channels, height, width)\n",
        "    to (n_samples, n_channels * height * width).\n",
        "    During backward pass, it reshapes the gradient back to the original shape.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.original_shape = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass: Flattens the input tensor.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : ndarray of shape (n_samples, n_channels, height, width)\n",
        "            Input tensor.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        flattened_x : ndarray of shape (n_samples, n_channels * height * width)\n",
        "            Flattened tensor.\n",
        "        \"\"\"\n",
        "        self.original_shape = x.shape\n",
        "        n_samples = x.shape[0]\n",
        "        flattened_x = x.reshape(n_samples, -1)\n",
        "        return flattened_x\n",
        "\n",
        "    def backward(self, da):\n",
        "        \"\"\"\n",
        "        Backward pass: Reshapes the gradient back to the original shape.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        da : ndarray of shape (n_samples, n_channels * height * width)\n",
        "            Gradient with respect to the flattened output.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        dx : ndarray of shape (n_samples, n_channels, height, width)\n",
        "            Gradient with respect to the original input shape.\n",
        "        \"\"\"\n",
        "        if self.original_shape is None:\n",
        "            raise ValueError(\"Original shape not stored. Forward pass must be called before backward.\")\n",
        "        dx = da.reshape(self.original_shape)\n",
        "        return dx\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Example usage:\n",
        "    x = np.random.rand(2, 3, 4, 4)\n",
        "    print(\"Original shape:\", x.shape)\n",
        "    print(\"Input:\\n\", x)\n",
        "\n",
        "    flatten_layer = Flatten()\n",
        "    flattened_output = flatten_layer.forward(x)\n",
        "    print(\"Flattened shape:\", flattened_output.shape)\n",
        "    print(\"Flattened Output:\\n\", flattened_output)\n",
        "\n",
        "    dout = np.random.rand(2, 3 * 4 * 4)\n",
        "    print(\"Gradient of the following layer (dout) shape:\", dout.shape)\n",
        "    print(\"dout:\\n\", dout)\n",
        "\n",
        "    din = flatten_layer.backward(dout)\n",
        "    print(\"Gradient of the input (din) shape:\", din.shape)\n",
        "    print(\"din:\\n\", din)\n",
        "\n",
        "    # Example with a different shape\n",
        "    y = np.random.rand(1, 1, 28, 28)\n",
        "    print(\"\\nOriginal shape (y):\", y.shape)\n",
        "    flattened_y = flatten_layer.forward(y)\n",
        "    print(\"Flattened shape (flattened_y):\", flattened_y.shape)\n",
        "    dout_y = np.random.rand(1, 1 * 28 * 28)\n",
        "    din_y = flatten_layer.backward(dout_y)\n",
        "    print(\"Gradient of the input (din_y) shape:\", din_y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-npmkv0GSJB",
        "outputId": "07b61328-8a41-40d2-e5a2-26a1037560f9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shape: (2, 3, 4, 4)\n",
            "Input:\n",
            " [[[[7.35607015e-01 3.17028548e-01 6.82923783e-01 7.24520752e-01]\n",
            "   [7.77717403e-04 1.43967432e-01 7.59855998e-01 1.71671799e-01]\n",
            "   [5.50528475e-01 2.93904110e-01 4.69574895e-01 7.12156737e-01]\n",
            "   [4.25998974e-02 4.09931452e-01 6.53097263e-01 5.48578487e-01]]\n",
            "\n",
            "  [[4.29252520e-01 4.33545861e-01 9.60185045e-02 5.96830267e-01]\n",
            "   [5.04137085e-01 4.39141834e-01 7.18515014e-02 7.91706855e-01]\n",
            "   [7.16735779e-01 2.63482227e-01 7.30861995e-01 6.53004818e-01]\n",
            "   [1.73617255e-02 4.49810258e-01 3.79557824e-01 9.14156521e-01]]\n",
            "\n",
            "  [[2.58634598e-03 8.29431888e-01 3.60113113e-01 3.80597397e-01]\n",
            "   [6.31668841e-01 7.59946022e-01 2.32501441e-01 6.51771875e-01]\n",
            "   [9.90624145e-02 1.65118967e-01 9.27820661e-01 6.30803147e-01]\n",
            "   [3.09840072e-01 8.73077633e-01 9.47167316e-04 2.62593635e-01]]]\n",
            "\n",
            "\n",
            " [[[5.95331040e-01 9.23429033e-01 3.90021523e-01 2.38354040e-01]\n",
            "   [9.68713951e-01 1.94899645e-01 6.53574158e-01 2.31971803e-01]\n",
            "   [7.82141455e-01 6.82350475e-01 2.54593896e-01 3.88059417e-03]\n",
            "   [2.09755663e-01 1.61468692e-01 7.22464917e-01 2.50672512e-01]]\n",
            "\n",
            "  [[5.69819619e-01 3.10643320e-01 5.20706774e-02 6.89394674e-01]\n",
            "   [2.84091204e-01 7.86283240e-01 9.63607132e-01 9.26256790e-01]\n",
            "   [5.35276187e-01 5.30904061e-01 6.89357853e-01 2.29700852e-02]\n",
            "   [1.38903431e-01 4.74192027e-01 6.58457541e-01 3.12430577e-01]]\n",
            "\n",
            "  [[5.98862858e-01 7.98492198e-01 4.39419586e-01 7.49436205e-01]\n",
            "   [9.88776350e-03 3.33053896e-01 5.67127162e-01 1.81271084e-01]\n",
            "   [1.27370196e-01 7.63562655e-01 7.60649328e-02 4.12176757e-01]\n",
            "   [4.53153395e-01 5.15871938e-01 6.53677994e-01 6.12358525e-01]]]]\n",
            "Flattened shape: (2, 48)\n",
            "Flattened Output:\n",
            " [[7.35607015e-01 3.17028548e-01 6.82923783e-01 7.24520752e-01\n",
            "  7.77717403e-04 1.43967432e-01 7.59855998e-01 1.71671799e-01\n",
            "  5.50528475e-01 2.93904110e-01 4.69574895e-01 7.12156737e-01\n",
            "  4.25998974e-02 4.09931452e-01 6.53097263e-01 5.48578487e-01\n",
            "  4.29252520e-01 4.33545861e-01 9.60185045e-02 5.96830267e-01\n",
            "  5.04137085e-01 4.39141834e-01 7.18515014e-02 7.91706855e-01\n",
            "  7.16735779e-01 2.63482227e-01 7.30861995e-01 6.53004818e-01\n",
            "  1.73617255e-02 4.49810258e-01 3.79557824e-01 9.14156521e-01\n",
            "  2.58634598e-03 8.29431888e-01 3.60113113e-01 3.80597397e-01\n",
            "  6.31668841e-01 7.59946022e-01 2.32501441e-01 6.51771875e-01\n",
            "  9.90624145e-02 1.65118967e-01 9.27820661e-01 6.30803147e-01\n",
            "  3.09840072e-01 8.73077633e-01 9.47167316e-04 2.62593635e-01]\n",
            " [5.95331040e-01 9.23429033e-01 3.90021523e-01 2.38354040e-01\n",
            "  9.68713951e-01 1.94899645e-01 6.53574158e-01 2.31971803e-01\n",
            "  7.82141455e-01 6.82350475e-01 2.54593896e-01 3.88059417e-03\n",
            "  2.09755663e-01 1.61468692e-01 7.22464917e-01 2.50672512e-01\n",
            "  5.69819619e-01 3.10643320e-01 5.20706774e-02 6.89394674e-01\n",
            "  2.84091204e-01 7.86283240e-01 9.63607132e-01 9.26256790e-01\n",
            "  5.35276187e-01 5.30904061e-01 6.89357853e-01 2.29700852e-02\n",
            "  1.38903431e-01 4.74192027e-01 6.58457541e-01 3.12430577e-01\n",
            "  5.98862858e-01 7.98492198e-01 4.39419586e-01 7.49436205e-01\n",
            "  9.88776350e-03 3.33053896e-01 5.67127162e-01 1.81271084e-01\n",
            "  1.27370196e-01 7.63562655e-01 7.60649328e-02 4.12176757e-01\n",
            "  4.53153395e-01 5.15871938e-01 6.53677994e-01 6.12358525e-01]]\n",
            "Gradient of the following layer (dout) shape: (2, 48)\n",
            "dout:\n",
            " [[0.09209384 0.52537492 0.66415048 0.60445177 0.40787356 0.12329436\n",
            "  0.62818636 0.53511532 0.1677083  0.55251249 0.24633354 0.89322836\n",
            "  0.84850497 0.11222579 0.03877248 0.74274902 0.9931914  0.15816655\n",
            "  0.31258791 0.97175852 0.75887855 0.27832271 0.37461689 0.10798234\n",
            "  0.7311091  0.47782249 0.483841   0.69497601 0.57448363 0.86421016\n",
            "  0.46090715 0.60760296 0.19178323 0.55015221 0.99856169 0.53606312\n",
            "  0.78034246 0.52538105 0.5399392  0.05138996 0.34407362 0.57167789\n",
            "  0.47294697 0.46744879 0.46939183 0.50628996 0.67815934 0.80423082]\n",
            " [0.3499213  0.74719958 0.37457148 0.93355593 0.2216655  0.66916183\n",
            "  0.95727073 0.02826833 0.71457924 0.19547985 0.62196452 0.10849418\n",
            "  0.9475701  0.72141018 0.28286345 0.37640382 0.81460968 0.70721249\n",
            "  0.06416072 0.79316923 0.26220663 0.11918052 0.55042854 0.22874064\n",
            "  0.85725619 0.88076952 0.7883168  0.76406496 0.50730439 0.73188214\n",
            "  0.56033318 0.40265678 0.7634474  0.81823205 0.23475049 0.57433895\n",
            "  0.51243257 0.01536598 0.93259335 0.5812456  0.5312895  0.53121141\n",
            "  0.41445611 0.92465704 0.36961143 0.55429119 0.12333671 0.92401595]]\n",
            "Gradient of the input (din) shape: (2, 3, 4, 4)\n",
            "din:\n",
            " [[[[0.09209384 0.52537492 0.66415048 0.60445177]\n",
            "   [0.40787356 0.12329436 0.62818636 0.53511532]\n",
            "   [0.1677083  0.55251249 0.24633354 0.89322836]\n",
            "   [0.84850497 0.11222579 0.03877248 0.74274902]]\n",
            "\n",
            "  [[0.9931914  0.15816655 0.31258791 0.97175852]\n",
            "   [0.75887855 0.27832271 0.37461689 0.10798234]\n",
            "   [0.7311091  0.47782249 0.483841   0.69497601]\n",
            "   [0.57448363 0.86421016 0.46090715 0.60760296]]\n",
            "\n",
            "  [[0.19178323 0.55015221 0.99856169 0.53606312]\n",
            "   [0.78034246 0.52538105 0.5399392  0.05138996]\n",
            "   [0.34407362 0.57167789 0.47294697 0.46744879]\n",
            "   [0.46939183 0.50628996 0.67815934 0.80423082]]]\n",
            "\n",
            "\n",
            " [[[0.3499213  0.74719958 0.37457148 0.93355593]\n",
            "   [0.2216655  0.66916183 0.95727073 0.02826833]\n",
            "   [0.71457924 0.19547985 0.62196452 0.10849418]\n",
            "   [0.9475701  0.72141018 0.28286345 0.37640382]]\n",
            "\n",
            "  [[0.81460968 0.70721249 0.06416072 0.79316923]\n",
            "   [0.26220663 0.11918052 0.55042854 0.22874064]\n",
            "   [0.85725619 0.88076952 0.7883168  0.76406496]\n",
            "   [0.50730439 0.73188214 0.56033318 0.40265678]]\n",
            "\n",
            "  [[0.7634474  0.81823205 0.23475049 0.57433895]\n",
            "   [0.51243257 0.01536598 0.93259335 0.5812456 ]\n",
            "   [0.5312895  0.53121141 0.41445611 0.92465704]\n",
            "   [0.36961143 0.55429119 0.12333671 0.92401595]]]]\n",
            "\n",
            "Original shape (y): (1, 1, 28, 28)\n",
            "Flattened shape (flattened_y): (1, 784)\n",
            "Gradient of the input (din_y) shape: (1, 1, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Verification\n",
        "###[Problem 7] Learning and estimation"
      ],
      "metadata": {
        "id": "GEhmL2J3G_Zr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load MNIST dataset (simplified for demonstration)\n",
        "def load_mnist(n_train=1000, n_test=500):\n",
        "    from tensorflow.keras.datasets import mnist\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "    # Normalize and reshape\n",
        "    x_train = x_train[:n_train].astype('float32') / 255.0\n",
        "    x_test = x_test[:n_test].astype('float32') / 255.0\n",
        "    x_train = x_train.reshape(-1, 1, 28, 28)\n",
        "    x_test = x_test.reshape(-1, 1, 28, 28)\n",
        "\n",
        "    # One-hot encode labels\n",
        "    encoder = OneHotEncoder(sparse_output=False)\n",
        "    y_train_encoded = encoder.fit_transform(y_train[:n_train].reshape(-1, 1))\n",
        "    y_test_encoded = encoder.transform(y_test[:n_test].reshape(-1, 1))\n",
        "\n",
        "    return x_train, y_train_encoded, x_test, y_test_encoded\n",
        "\n",
        "class Conv2d:\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, lr=0.01):\n",
        "        if isinstance(kernel_size, int):\n",
        "            kernel_size = (kernel_size, kernel_size)\n",
        "        if isinstance(stride, int):\n",
        "            stride = (stride, stride)\n",
        "        if isinstance(padding, int):\n",
        "            padding = (padding, padding)\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_h, self.kernel_w = kernel_size\n",
        "        self.stride_h, self.stride_w = stride\n",
        "        self.padding_h, self.padding_w = padding\n",
        "        self.lr = lr\n",
        "        self.W = np.random.randn(out_channels, in_channels, self.kernel_h, self.kernel_w) * 0.01\n",
        "        self.b = np.zeros(out_channels)\n",
        "        self.dW = np.zeros_like(self.W)\n",
        "        self.db = np.zeros_like(self.b)\n",
        "        self.x = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "        n_samples, in_channels, height, width = x.shape\n",
        "        out_h = (height + 2 * self.padding_h - self.kernel_h) // self.stride_h + 1\n",
        "        out_w = (width + 2 * self.padding_w - self.kernel_w) // self.stride_w + 1\n",
        "        a = np.zeros((n_samples, self.out_channels, out_h, out_w))\n",
        "        x_padded = np.pad(x, [(0, 0), (0, 0), (self.padding_h, self.padding_h), (self.padding_w, self.padding_w)], 'constant')\n",
        "\n",
        "        for n in range(n_samples):\n",
        "            for oc in range(self.out_channels):\n",
        "                for i in range(out_h):\n",
        "                    for j in range(out_w):\n",
        "                        h_start = i * self.stride_h\n",
        "                        h_end = h_start + self.kernel_h\n",
        "                        w_start = j * self.stride_w\n",
        "                        w_end = w_start + self.kernel_w\n",
        "                        a[n, oc, i, j] = np.sum(x_padded[n, :, h_start:h_end, w_start:w_end] * self.W[oc, :, :, :]) + self.b[oc]\n",
        "        return a\n",
        "\n",
        "    def backward(self, da):\n",
        "        n_samples, out_channels, out_h, out_w = da.shape\n",
        "        in_channels, in_h, in_w = self.x.shape[1:]\n",
        "        self.dW = np.zeros_like(self.W)\n",
        "        self.db = np.sum(da, axis=(0, 2, 3))\n",
        "\n",
        "        x_padded = np.pad(self.x, [(0, 0), (0, 0), (self.padding_h, self.padding_h), (self.padding_w, self.padding_w)], 'constant')\n",
        "        dx = np.zeros_like(self.x)\n",
        "        dx_padded = np.pad(dx, [(0, 0), (0, 0), (self.padding_h, self.padding_h), (self.padding_w, self.padding_w)], 'constant')\n",
        "\n",
        "        for n in range(n_samples):\n",
        "            for oc in range(out_channels):\n",
        "                for ic in range(in_channels):\n",
        "                    for kh in range(self.kernel_h):\n",
        "                        for kw in range(self.kernel_w):\n",
        "                            for i in range(out_h):\n",
        "                                for j in range(out_w):\n",
        "                                    h_start = i * self.stride_h\n",
        "                                    h_in = h_start + kh\n",
        "                                    w_start = j * self.stride_w\n",
        "                                    w_in = w_start + kw\n",
        "                                    if (0 <= h_in < in_h + 2 * self.padding_h and\n",
        "                                        0 <= w_in < in_w + 2 * self.padding_w):\n",
        "                                        self.dW[oc, ic, kh, kw] += da[n, oc, i, j] * x_padded[n, ic, h_in, w_in]\n",
        "\n",
        "        for n in range(n_samples):\n",
        "            for ic in range(in_channels):\n",
        "                for oc in range(out_channels):\n",
        "                    for kh in range(self.kernel_h):\n",
        "                        for kw in range(self.kernel_w):\n",
        "                            for i in range(out_h):\n",
        "                                for j in range(out_w):\n",
        "                                    h_out = i * self.stride_h\n",
        "                                    h_in = h_out + kh\n",
        "                                    w_out = j * self.stride_w\n",
        "                                    w_in = w_out + kw\n",
        "                                    if (0 <= h_in < in_h + 2 * self.padding_h and\n",
        "                                        0 <= w_in < in_w + 2 * self.padding_w):\n",
        "                                        dx_padded[n, ic, h_in, w_in] += da[n, oc, i, j] * self.W[oc, ic, kh, kw]\n",
        "\n",
        "        if self.padding_h > 0 or self.padding_w > 0:\n",
        "            dx = dx_padded[:, :, self.padding_h:-self.padding_h, self.padding_w:-self.padding_w]\n",
        "        else:\n",
        "            dx = dx_padded\n",
        "\n",
        "        return dx\n",
        "\n",
        "    def update(self):\n",
        "        self.W -= self.lr * self.dW\n",
        "        self.b -= self.lr * self.db\n",
        "\n",
        "class ReLU:\n",
        "    def forward(self, x):\n",
        "        self.mask = (x <= 0)\n",
        "        return np.maximum(0, x)\n",
        "\n",
        "    def backward(self, da):\n",
        "        da[self.mask] = 0\n",
        "        return da\n",
        "\n",
        "class Flatten:\n",
        "    def forward(self, x):\n",
        "        self.original_shape = x.shape\n",
        "        n_samples = x.shape[0]\n",
        "        return x.reshape(n_samples, -1)\n",
        "\n",
        "    def backward(self, da):\n",
        "        return da.reshape(self.original_shape)\n",
        "\n",
        "class Dense:\n",
        "    def __init__(self, in_size, out_size, lr=0.01):\n",
        "        self.W = np.random.randn(in_size, out_size) * 0.01\n",
        "        self.b = np.zeros(out_size)\n",
        "        self.dW = np.zeros_like(self.W)\n",
        "        self.db = np.zeros_like(self.b)\n",
        "        self.lr = lr\n",
        "        self.x = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "        return np.dot(x, self.W) + self.b\n",
        "\n",
        "    def backward(self, da):\n",
        "        self.dW = np.dot(self.x.T, da)\n",
        "        self.db = np.sum(da, axis=0)\n",
        "        dx = np.dot(da, self.W.T)\n",
        "        return dx\n",
        "\n",
        "    def update(self):\n",
        "        self.W -= self.lr * self.dW\n",
        "        self.b -= self.lr * self.db\n",
        "\n",
        "class SoftmaxWithLoss:\n",
        "    def __init__(self):\n",
        "        self.loss = None\n",
        "        self.y_pred = None\n",
        "        self.y_true = None\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        self.y_true = t\n",
        "        exp_a = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "        self.y_pred = exp_a / np.sum(exp_a, axis=1, keepdims=True)\n",
        "        batch_size = self.y_pred.shape[0]\n",
        "        cross_entropy_loss = -np.sum(t * np.log(self.y_pred + 1e-7)) / batch_size\n",
        "        self.loss = cross_entropy_loss\n",
        "        return self.loss\n",
        "\n",
        "    def backward(self, dout=1):\n",
        "        batch_size = self.y_true.shape[0]\n",
        "        dx = (self.y_pred - self.y_true) * dout / batch_size\n",
        "        return dx\n",
        "\n",
        "class SimpleCNN:\n",
        "    def __init__(self, lr=0.01):\n",
        "        self.lr = lr\n",
        "        self.conv1 = Conv2d(1, 8, 3, padding=1, lr=lr)\n",
        "        self.relu1 = ReLU()\n",
        "        self.flatten = Flatten()\n",
        "        self.fc1 = Dense(8 * 28 * 28, 10, lr=lr) # No pooling for simplicity in this minimal example\n",
        "        self.loss_layer = SoftmaxWithLoss()\n",
        "\n",
        "    def predict(self, x):\n",
        "        out = self.conv1.forward(x)\n",
        "        out = self.relu1.forward(out)\n",
        "        out = self.flatten.forward(out)\n",
        "        out = self.fc1.forward(out)\n",
        "        return np.argmax(out, axis=1)\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        out = self.conv1.forward(x)\n",
        "        out = self.relu1.forward(out)\n",
        "        out = self.flatten.forward(out)\n",
        "        out = self.fc1.forward(out)\n",
        "        loss = self.loss_layer.forward(out, t)\n",
        "        return loss\n",
        "\n",
        "    def backward(self, dout=1):\n",
        "        dout = self.loss_layer.backward(dout)\n",
        "        dout = self.fc1.backward(dout)\n",
        "        dout = self.flatten.backward(dout)\n",
        "        dout = self.relu1.backward(dout)\n",
        "        dout = self.conv1.backward(dout)\n",
        "        return dout\n",
        "\n",
        "    def update(self):\n",
        "        self.conv1.update()\n",
        "        self.fc1.update()\n",
        "\n",
        "def train(model, x_train, t_train, epochs=5, batch_size=32):\n",
        "    n_train = x_train.shape[0]\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0\n",
        "        for i in tqdm(range(0, n_train, batch_size), desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
        "            batch_x = x_train[i:i + batch_size]\n",
        "            batch_t = t_train[i:i + batch_size]\n",
        "\n",
        "            loss = model.forward(batch_x, batch_t)\n",
        "            model.backward()\n",
        "            model.update()\n",
        "            epoch_loss += loss\n",
        "\n",
        "        avg_loss = epoch_loss / (n_train // batch_size)\n",
        "        print(f\"Epoch {epoch+1} Loss: {avg_loss:.4f}\")\n",
        "\n",
        "def evaluate(model, x_test, t_test):\n",
        "    y_pred = model.predict(x_test)\n",
        "    y_true = np.argmax(t_test, axis=1)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    return accuracy\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Load a small subset of MNIST for faster training\n",
        "    x_train, t_train, x_test, t_test = load_mnist(n_train=1000, n_test=500)\n",
        "\n",
        "    # Initialize the simple CNN model\n",
        "    model = SimpleCNN(lr=0.01)\n",
        "\n",
        "    # Train the model\n",
        "    train(model, x_train, t_train, epochs=5, batch_size=32)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = evaluate(model, x_test, t_test)\n",
        "    print(f\"\\nTest Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IbgZhOLG9F9",
        "outputId": "fd68882c-6e6b-4923-840e-85aaa5a02602"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5: 100%|██████████| 32/32 [03:28<00:00,  6.51s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Loss: 2.3760\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 100%|██████████| 32/32 [03:27<00:00,  6.48s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Loss: 2.3722\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 100%|██████████| 32/32 [03:26<00:00,  6.45s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Loss: 2.3582\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 100%|██████████| 32/32 [03:25<00:00,  6.43s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 Loss: 2.2931\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 100%|██████████| 32/32 [03:26<00:00,  6.44s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 Loss: 2.0251\n",
            "\n",
            "Test Accuracy: 0.5620\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###[Problem 8] (Advanced assignment) LeNet"
      ],
      "metadata": {
        "id": "2MSMQBiuHdCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "def load_mnist_lenet(n_train=60000, n_test=10000):\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "    # Normalize and reshape for LeNet input (1 channel)\n",
        "    x_train = x_train[:n_train].astype('float32') / 255.0\n",
        "    x_test = x_test[:n_test].astype('float32') / 255.0\n",
        "    x_train = x_train.reshape(-1, 1, 28, 28)\n",
        "    x_test = x_test.reshape(-1, 1, 28, 28)\n",
        "\n",
        "    # One-hot encode labels\n",
        "    encoder = OneHotEncoder(sparse_output=False)\n",
        "    y_train_encoded = encoder.fit_transform(y_train[:n_train].reshape(-1, 1))\n",
        "    y_test_encoded = encoder.transform(y_test[:n_test].reshape(-1, 1))\n",
        "\n",
        "    return x_train, y_train_encoded, x_test, y_test_encoded\n",
        "\n",
        "class Conv2d:\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, lr=0.01):\n",
        "        if isinstance(kernel_size, int):\n",
        "            kernel_size = (kernel_size, kernel_size)\n",
        "        if isinstance(stride, int):\n",
        "            stride = (stride, stride)\n",
        "        if isinstance(padding, int):\n",
        "            padding = (padding, padding)\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_h, self.kernel_w = kernel_size\n",
        "        self.stride_h, self.stride_w = stride\n",
        "        self.padding_h, self.padding_w = padding\n",
        "        self.lr = lr\n",
        "        self.W = np.random.randn(out_channels, in_channels, self.kernel_h, self.kernel_w) * 0.01\n",
        "        self.b = np.zeros(out_channels)\n",
        "        self.dW = np.zeros_like(self.W)\n",
        "        self.db = np.zeros_like(self.b)\n",
        "        self.x = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "        n_samples, in_channels, height, width = x.shape\n",
        "        out_h = (height + 2 * self.padding_h - self.kernel_h) // self.stride_h + 1\n",
        "        out_w = (width + 2 * self.padding_w - self.kernel_w) // self.stride_w + 1\n",
        "        a = np.zeros((n_samples, self.out_channels, out_h, out_w))\n",
        "        x_padded = np.pad(x, [(0, 0), (0, 0), (self.padding_h, self.padding_h), (self.padding_w, self.padding_w)], 'constant')\n",
        "\n",
        "        for n in range(n_samples):\n",
        "            for oc in range(self.out_channels):\n",
        "                for i in range(out_h):\n",
        "                    for j in range(out_w):\n",
        "                        h_start = i * self.stride_h\n",
        "                        h_end = h_start + self.kernel_h\n",
        "                        w_start = j * self.stride_w\n",
        "                        w_end = w_start + self.kernel_w\n",
        "                        a[n, oc, i, j] = np.sum(x_padded[n, :, h_start:h_end, w_start:w_end] * self.W[oc, :, :, :]) + self.b[oc]\n",
        "        return a\n",
        "\n",
        "    def backward(self, da):\n",
        "        n_samples, out_channels, out_h, out_w = da.shape\n",
        "        in_channels, in_h, in_w = self.x.shape[1:]\n",
        "        self.dW = np.zeros_like(self.W)\n",
        "        self.db = np.sum(da, axis=(0, 2, 3))\n",
        "\n",
        "        x_padded = np.pad(self.x, [(0, 0), (0, 0), (self.padding_h, self.padding_h), (self.padding_w, self.padding_w)], 'constant')\n",
        "        dx = np.zeros_like(self.x)\n",
        "        dx_padded = np.pad(dx, [(0, 0), (0, 0), (self.padding_h, self.padding_h), (self.padding_w, self.padding_w)], 'constant')\n",
        "\n",
        "        for n in range(n_samples):\n",
        "            for oc in range(out_channels):\n",
        "                for ic in range(in_channels):\n",
        "                    for kh in range(self.kernel_h):\n",
        "                        for kw in range(self.kernel_w):\n",
        "                            for i in range(out_h):\n",
        "                                for j in range(out_w):\n",
        "                                    h_start = i * self.stride_h\n",
        "                                    h_in = h_start + kh\n",
        "                                    w_start = j * self.stride_w\n",
        "                                    w_in = w_start + kw\n",
        "                                    if (0 <= h_in < in_h + 2 * self.padding_h and\n",
        "                                        0 <= w_in < in_w + 2 * self.padding_w):\n",
        "                                        self.dW[oc, ic, kh, kw] += da[n, oc, i, j] * x_padded[n, ic, h_in, w_in]\n",
        "\n",
        "        for n in range(n_samples):\n",
        "            for ic in range(in_channels):\n",
        "                for oc in range(out_channels):\n",
        "                    for kh in range(self.kernel_h):\n",
        "                        for kw in range(self.kernel_w):\n",
        "                            for i in range(out_h):\n",
        "                                for j in range(out_w):\n",
        "                                    h_out = i * self.stride_h\n",
        "                                    h_in = h_out + kh\n",
        "                                    w_out = j * self.stride_w\n",
        "                                    w_in = w_out + kw\n",
        "                                    if (0 <= h_in < in_h + 2 * self.padding_h and\n",
        "                                        0 <= w_in < in_w + 2 * self.padding_w):\n",
        "                                        dx_padded[n, ic, h_in, w_in] += da[n, oc, i, j] * self.W[oc, ic, kh, kw]\n",
        "\n",
        "        if self.padding_h > 0 or self.padding_w > 0:\n",
        "            dx = dx_padded[:, :, self.padding_h:-self.padding_h, self.padding_w:-self.padding_w]\n",
        "        else:\n",
        "            dx = dx_padded\n",
        "\n",
        "        return dx\n",
        "\n",
        "    def update(self):\n",
        "        self.W -= self.lr * self.dW\n",
        "        self.b -= self.lr * self.db\n",
        "\n",
        "class ReLU:\n",
        "    def forward(self, x):\n",
        "        self.mask = (x <= 0)\n",
        "        return np.maximum(0, x)\n",
        "\n",
        "    def backward(self, da):\n",
        "        da[self.mask] = 0\n",
        "        return da\n",
        "\n",
        "class MaxPool2D:\n",
        "    def __init__(self, pool_size, stride=None):\n",
        "        self.pool_h, self.pool_w = pool_size\n",
        "        if stride is None:\n",
        "            self.stride_h, self.stride_w = self.pool_h, self.pool_w\n",
        "        else:\n",
        "            self.stride_h, self.stride_w = stride\n",
        "        self.x = None\n",
        "        self.arg_max = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "        n_samples, n_channels, height, width = x.shape\n",
        "        output_height = (height - self.pool_h) // self.stride_h + 1\n",
        "        output_width = (width - self.pool_w) // self.stride_w + 1\n",
        "        a = np.zeros((n_samples, n_channels, output_height, output_width))\n",
        "        self.arg_max = np.zeros_like(a, dtype=int)\n",
        "\n",
        "        for i in range(output_height):\n",
        "            for j in range(output_width):\n",
        "                h_start = i * self.stride_h\n",
        "                h_end = h_start + self.pool_h\n",
        "                w_start = j * self.stride_w\n",
        "                w_end = w_start + self.pool_w\n",
        "\n",
        "                pool_region = x[:, :, h_start:h_end, w_start:w_end]\n",
        "                a[:, :, i, j] = np.max(pool_region, axis=(2, 3))\n",
        "                arg_max_local = np.argmax(pool_region.reshape(n_samples, n_channels, -1), axis=2)\n",
        "                self.arg_max[:, :, i, j] = arg_max_local\n",
        "        return a\n",
        "\n",
        "    def backward(self, da):\n",
        "        dx = np.zeros_like(self.x, dtype=np.float64)\n",
        "        n_samples, n_channels, height, width = self.x.shape\n",
        "        output_height, output_width = da.shape[2:]\n",
        "\n",
        "        for i in range(output_height):\n",
        "            for j in range(output_width):\n",
        "                h_start = i * self.stride_h\n",
        "                h_end = h_start + self.pool_h\n",
        "                w_start = j * self.stride_w\n",
        "                w_end = w_start + self.pool_w\n",
        "\n",
        "                mask = np.zeros((n_samples, n_channels, self.pool_h, self.pool_w))\n",
        "                arg_max_local = self.arg_max[:, :, i, j]\n",
        "                row_index = arg_max_local // self.pool_w\n",
        "                col_index = arg_max_local % self.pool_w\n",
        "\n",
        "                for ns in range(n_samples):\n",
        "                    for nc in range(n_channels):\n",
        "                        mask[ns, nc, row_index[ns, nc], col_index[ns, nc]] = 1\n",
        "\n",
        "                dx[:, :, h_start:h_end, w_start:w_end] += da[:, :, i, j][:, :, np.newaxis, np.newaxis] * mask\n",
        "        return dx\n",
        "\n",
        "class Flatten:\n",
        "    def forward(self, x):\n",
        "        self.original_shape = x.shape\n",
        "        n_samples = x.shape[0]\n",
        "        return x.reshape(n_samples, -1)\n",
        "\n",
        "    def backward(self, da):\n",
        "        return da.reshape(self.original_shape)\n",
        "\n",
        "class Dense:\n",
        "    def __init__(self, in_size, out_size, lr=0.01):\n",
        "        self.W = np.random.randn(in_size, out_size) * 0.01\n",
        "        self.b = np.zeros(out_size)\n",
        "        self.dW = np.zeros_like(self.W)\n",
        "        self.db = np.zeros_like(self.b)\n",
        "        self.lr = lr\n",
        "        self.x = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "        return np.dot(x, self.W) + self.b\n",
        "\n",
        "    def backward(self, da):\n",
        "        self.dW = np.dot(self.x.T, da)\n",
        "        self.db = np.sum(da, axis=0)\n",
        "        dx = np.dot(da, self.W.T)\n",
        "        return dx\n",
        "\n",
        "    def update(self):\n",
        "        self.W -= self.lr * self.dW\n",
        "        self.b -= self.lr * self.db\n",
        "\n",
        "class Softmax:\n",
        "    def forward(self, x):\n",
        "        exp_a = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "        self.y = exp_a / np.sum(exp_a, axis=1, keepdims=True)\n",
        "        return self.y\n",
        "\n",
        "    def backward(self, dout):\n",
        "        batch_size = dout.shape[0]\n",
        "        dx = (self.y - np.argmax(self.y, axis=1)[:, np.newaxis]) * dout / batch_size # Simplified for classification\n",
        "        return dx\n",
        "\n",
        "class SoftmaxWithLoss:\n",
        "    def __init__(self):\n",
        "        self.loss = None\n",
        "        self.y_pred = None\n",
        "        self.y_true = None\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        self.y_true = t\n",
        "        exp_a = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "        self.y_pred = exp_a / np.sum(exp_a, axis=1, keepdims=True)\n",
        "        batch_size = self.y_pred.shape[0]\n",
        "        cross_entropy_loss = -np.sum(t * np.log(self.y_pred + 1e-7)) / batch_size\n",
        "        self.loss = cross_entropy_loss\n",
        "        return self.loss\n",
        "\n",
        "    def backward(self, dout=1):\n",
        "        batch_size = self.y_true.shape[0]\n",
        "        dx = (self.y_pred - self.y_true) * dout / batch_size\n",
        "        return dx\n",
        "\n",
        "class LeNet5:\n",
        "    def __init__(self, lr=0.01):\n",
        "        self.lr = lr\n",
        "        # Layer 1: Convolutional (6 output channels, 5x5 kernel, stride 1)\n",
        "        self.conv1 = Conv2d(1, 6, 5, stride=1, padding=0, lr=lr)\n",
        "        self.relu1 = ReLU()\n",
        "        # Layer 2: Max Pooling (2x2 pool size, stride 2)\n",
        "        self.pool2 = MaxPool2D(pool_size=(2, 2), stride=(2, 2))\n",
        "        # Layer 3: Convolutional (16 output channels, 5x5 kernel, stride 1)\n",
        "        self.conv3 = Conv2d(6, 16, 5, stride=1, padding=0, lr=lr)\n",
        "        self.relu3 = ReLU()\n",
        "        # Layer 4: Max Pooling (2x2 pool size, stride 2)\n",
        "        self.pool4 = MaxPool2D(pool_size=(2, 2), stride=(2, 2))\n",
        "        # Layer 5: Flatten\n",
        "        self.flatten5 = Flatten()\n",
        "        # Layer 6: Fully Connected (120 output nodes)\n",
        "        self.fc6 = Dense(16 * 5 * 5, 120, lr=lr)\n",
        "        self.relu6 = ReLU()\n",
        "        # Layer 7: Fully Connected (84 output nodes)\n",
        "        self.fc7 = Dense(120, 84, lr=lr)\n",
        "        self.relu7 = ReLU()\n",
        "        # Layer 8: Fully Connected (10 output nodes)\n",
        "        self.fc8 = Dense(84, 10, lr=lr)\n",
        "        # Layer 9: Softmax with Loss\n",
        "        self.loss_layer = SoftmaxWithLoss()\n",
        "\n",
        "    def predict(self, x):\n",
        "        out = self.conv1.forward(x)\n",
        "        out = self.relu1.forward(out)\n",
        "        out = self.pool2.forward(out)\n",
        "        out = self.conv3.forward(out)\n",
        "        out = self.relu3.forward(out)\n",
        "        out = self.pool4.forward(out)\n",
        "        out = self.flatten5.forward(out)\n",
        "        out = self.fc6.forward(out)\n",
        "        out = self.relu6.forward(out)\n",
        "        out = self.fc7.forward(out)\n",
        "        out = self.relu7.forward(out)\n",
        "        out = self.fc8.forward(out)\n",
        "        return np.argmax(out, axis=1)\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        out = self.conv1.forward(x)\n",
        "        out = self.relu1.forward(out)\n",
        "        out = self.pool2.forward(out)\n",
        "        out = self.conv3.forward(out)\n",
        "        out = self.relu3.forward(out)\n",
        "        out = self.pool4.forward(out)\n",
        "        out = self.flatten5.forward(out)\n",
        "        out = self.fc6.forward(out)\n",
        "        out = self.relu6.forward(out)\n",
        "        out = self.fc7.forward(out)\n",
        "        out = self.relu7.forward(out)\n",
        "        out = self.fc8.forward(out)\n",
        "        loss = self.loss_layer.forward(out, t)\n",
        "        return loss\n",
        "\n",
        "    def backward(self, dout=1):\n",
        "        dout = self.loss_layer.backward(dout)\n",
        "        dout = self.fc8.backward(dout)\n",
        "        dout = self.relu7.backward(dout)\n",
        "        dout = self.fc7.backward(dout)\n",
        "        dout = self.relu6.backward(dout)\n",
        "        dout = self.fc6.backward(dout)\n",
        "        dout = self.flatten5.backward(dout)\n",
        "        dout = self.pool4.backward(dout)\n",
        "        dout = self.relu3.backward(dout)\n",
        "        dout = self.conv3"
      ],
      "metadata": {
        "id": "qdWllkHCHVLm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###[Problem 9] (Advanced task) Research into famous image recognition models\n",
        "\n",
        "Here's what's readily available in Keras (which is a popular high-level API for building neural networks, often used with TensorFlow or other backends):\n",
        "\n",
        "**Pre-trained models available in Keras**\n",
        "\n",
        "Keras provides a wide range of pre-trained models that you can directly use for feature extraction or fine-tuning. These include the famous architectures you mentioned and many others:\n",
        "\n",
        "* **Xception:** A deep convolutional neural network architecture.\n",
        "* **VGG16 & VGG19:** Very Deep Convolutional Networks with 16 and 19 layers respectively. These were very influential in popularizing deep CNNs.\n",
        "* **ResNet50, ResNet101, ResNet152, ResNet50V2, ResNet101V2, ResNet152V2:** Deep residual networks that address the vanishing gradient problem and enable training of much deeper networks.\n",
        "* **InceptionV3, InceptionResNetV2:** Architectures that use inception modules to efficiently capture features at different scales.\n",
        "* **MobileNetV1, MobileNetV2, MobileNetV3:** Lightweight and efficient CNN architectures designed for mobile and embedded vision applications.\n",
        "* **DenseNet121, DenseNet169, DenseNet201, DenseNet264:** Densely connected convolutional networks where each layer is connected to all preceding layers.\n",
        "* **NASNetMobile, NASNetLarge:** Neural Architecture Search Networks that were automatically discovered.\n",
        "* **EfficientNetB0 to EfficientNetB7:** A family of models that systematically scale network dimensions (depth, width, and resolution) for better efficiency and accuracy.\n",
        "* **ConvNeXtBase, ConvNeXtSmall, ConvNeXtTiny, ConvNeXtLarge, ConvNeXtXLarge:** Modernized ResNet-like architectures inspired by the Transformer design.\n",
        "\n",
        "**Key Takeaways:**\n",
        "\n",
        "* **AlexNet (2012):** While historically significant, AlexNet itself isn't directly available as a pre-built model in the main Keras Applications. However, its architecture and influence are foundational to many of the available models. You might find implementations in the broader TensorFlow ecosystem or in educational examples.\n",
        "* **VGG16 (2014):** Yes, VGG16 (and its deeper variant VGG19) are readily available in Keras Applications.\n",
        "\n",
        "**In summary, Keras provides a rich collection of pre-trained CNN architectures, including VGG16 (as you asked), and many more modern and efficient models that have built upon the foundational work of networks like AlexNet.** This allows developers to leverage state-of-the-art features without having to train these large models from scratch."
      ],
      "metadata": {
        "id": "mdnOC581OD0V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###[Problem 10] Calculating the output size and number of parameters\n",
        "\n",
        "To calculate the output size and the number of parameters for each of the convolutional layers you described.\n",
        "\n",
        "**Key Formulas:**\n",
        "\n",
        "* **Output Height ($N_{h,out}$):** $\\lfloor \\frac{N_{h,in} + 2P_h - F_h}{S_h} + 1 \\rfloor$\n",
        "* **Output Width ($N_{w,out}$):** $\\lfloor \\frac{N_{w,in} + 2P_w - F_w}{S_w} + 1 \\rfloor$\n",
        "* **Number of Parameters:** $(F_h \\times F_w \\times N_{in\\_channels} + 1) \\times N_{out\\_channels}$\n",
        "    * $(F_h \\times F_w \\times N_{in\\_channels})$: Number of weights per filter.\n",
        "    * $+ 1$: Accounts for the bias term for each filter.\n",
        "    * $\\times N_{out\\_channels}$: Multiplied by the number of filters (output channels).\n",
        "\n",
        "**1. Input size: 144×144, 3 channels**\n",
        "   * Filter size: 3×3, 6 channels\n",
        "   * Stride: 1\n",
        "   * Padding: None ($P_h = 0, P_w = 0$)\n",
        "\n",
        "   * **Output Size:**\n",
        "      * $N_{h,out} = \\lfloor \\frac{144 + 2 \\times 0 - 3}{1} + 1 \\rfloor = \\lfloor 141 + 1 \\rfloor = 142$\n",
        "      * $N_{w,out} = \\lfloor \\frac{144 + 2 \\times 0 - 3}{1} + 1 \\rfloor = \\lfloor 141 + 1 \\rfloor = 142$\n",
        "      * **Output size:** 142×142, 6 channels\n",
        "\n",
        "   * **Number of Parameters:**\n",
        "      * $(3 \\times 3 \\times 3 + 1) \\times 6 = (27 + 1) \\times 6 = 28 \\times 6 = 168$\n",
        "      * **Number of parameters:** 168\n",
        "\n",
        "**2. Input size: 60×60, 24 channels**\n",
        "   * Filter size: 3×3, 48 channels\n",
        "   * Stride: 1\n",
        "   * Padding: None ($P_h = 0, P_w = 0$)\n",
        "\n",
        "   * **Output Size:**\n",
        "      * $N_{h,out} = \\lfloor \\frac{60 + 2 \\times 0 - 3}{1} + 1 \\rfloor = \\lfloor 57 + 1 \\rfloor = 58$\n",
        "      * $N_{w,out} = \\lfloor \\frac{60 + 2 \\times 0 - 3}{1} + 1 \\rfloor = \\lfloor 57 + 1 \\rfloor = 58$\n",
        "      * **Output size:** 58×58, 48 channels\n",
        "\n",
        "   * **Number of Parameters:**\n",
        "      * $(3 \\times 3 \\times 24 + 1) \\times 48 = (216 + 1) \\times 48 = 217 \\times 48 = 10416$\n",
        "      * **Number of parameters:** 10416\n",
        "\n",
        "**3. Input size: 20×20, 10 channels**\n",
        "   * Filter size: 3×3, 20 channels\n",
        "   * Stride: 2\n",
        "   * Padding: None ($P_h = 0, P_w = 0$)\n",
        "\n",
        "   * **Output Size:**\n",
        "      * $N_{h,out} = \\lfloor \\frac{20 + 2 \\times 0 - 3}{2} + 1 \\rfloor = \\lfloor \\frac{17}{2} + 1 \\rfloor = \\lfloor 8.5 + 1 \\rfloor = \\lfloor 9.5 \\rfloor = 9$\n",
        "      * $N_{w,out} = \\lfloor \\frac{20 + 2 \\times 0 - 3}{2} + 1 \\rfloor = \\lfloor \\frac{17}{2} + 1 \\rfloor = \\lfloor 8.5 + 1 \\rfloor = \\lfloor 9.5 \\rfloor = 9$\n",
        "      * **Output size:** 9×9, 20 channels\n",
        "\n",
        "   * **Number of Parameters:**\n",
        "      * $(3 \\times 3 \\times 10 + 1) \\times 20 = (90 + 1) \\times 20 = 91 \\times 20 = 1820$\n",
        "      * **Number of parameters:** 1820\n",
        "\n",
        "**Summary:**\n",
        "\n",
        "1.  **Layer 1:**\n",
        "    * **Output Size:** 142×142, 6 channels\n",
        "    * **Number of Parameters:** 168\n",
        "2.  **Layer 2:**\n",
        "    * **Output Size:** 58×58, 48 channels\n",
        "    * **Number of Parameters:** 10416\n",
        "3.  **Layer 3:**\n",
        "    * **Output Size:** 9×9, 20 channels\n",
        "    * **Number of Parameters:** 1820\n",
        "\n",
        "For the third example, as you mentioned, the convolution doesn't perfectly align with the input size and stride. The output size calculation using the floor function (`\\lfloor \\rfloor`) reflects how a typical framework would handle this by only performing the convolution on the parts of the input where the filter fully fits within the boundaries at the given stride. This results in the edges of the input being effectively \"clipped\" or not fully processed by the convolution operation in this specific layer configuration."
      ],
      "metadata": {
        "id": "aUalhBcnPKcw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###[Problem 11] (Advanced) Investigation into filter size"
      ],
      "metadata": {
        "id": "8A8ALyq-Ppk0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Why are 3x3 filters more commonly used than larger ones like 7x7?**\n",
        "\n",
        "While larger filters like 7x7 might seem beneficial for capturing broader spatial relationships in an image in a single layer, several key factors have led to the widespread adoption of smaller 3x3 filters:\n",
        "\n",
        "1.  **Increased Depth for the Same Receptive Field:** A stack of multiple 3x3 convolutional layers can achieve the same receptive field as a single larger filter but with greater depth. For example, two consecutive 3x3 layers have a receptive field of 5x5, and three consecutive 3x3 layers have a receptive field of 7x7.\n",
        "\n",
        "2.  **More Non-linearities:** Using multiple 3x3 layers introduces more non-linear activation functions (like ReLU) into the network. More non-linearities allow the network to learn more complex and intricate features compared to a single layer with a large filter. Each ReLU layer adds a point where the network can make a non-linear decision.\n",
        "\n",
        "3.  **Fewer Parameters:** A stack of smaller filters generally has fewer parameters than a single larger filter with the same receptive field. Consider a receptive field of 7x7 with $C_{in}$ input channels and $C_{out}$ output channels:\n",
        "    * A single 7x7 filter has $(7 \\times 7 \\times C_{in} + 1) \\times C_{out}$ parameters.\n",
        "    * Three stacked 3x3 filters (to achieve a 7x7 receptive field) have $3 \\times (3 \\times 3 \\times C_{in} + 1) \\times C_{mid} + 3 \\times (3 \\times 3 \\times C_{mid} + 1) \\times C_{mid} + (3 \\times 3 \\times C_{mid} + 1) \\times C_{out}$ parameters (if we assume an intermediate number of channels $C_{mid}$). Even with $C_{mid} = C_{in} = C_{out}$, the number of parameters for the 3x3 stack ($3 \\times (9C + 1)C$) is less than the 7x7 filter ($49C^2 + C$) for reasonably sized $C$. Fewer parameters help in reducing the risk of overfitting, especially when dealing with limited training data.\n",
        "\n",
        "4.  **Computational Efficiency:** Fewer parameters often translate to fewer computations during both the forward and backward passes, leading to faster training and inference times.\n",
        "\n",
        "In essence, using a stack of smaller 3x3 filters allows for building deeper and more expressive networks with better learning capacity and efficiency compared to using a single large filter to achieve the same receptive field.\n",
        "\n",
        "**The effect of a 1×1 filter with no height or width:**\n",
        "\n",
        "While a 1x1 filter might seem trivial at first glance, lacking spatial extent within a feature map, it plays a crucial role in modern CNN architectures, primarily for **channel-wise transformations and dimensionality manipulation**. Here's a breakdown of its effects:\n",
        "\n",
        "1.  **Channel-wise Linear Transformation:** A 1x1 convolution applies a linear combination across the channels of the input feature map at each spatial location (pixel). Each filter in the 1x1 convolutional layer learns a set of weights that determine how to combine the input channels to produce a new output channel.\n",
        "\n",
        "2.  **Dimensionality Reduction (Bottlenecking):** 1x1 convolutions can be used to reduce the number of channels in a feature map. If a 1x1 convolutional layer has fewer output channels than input channels, it creates a \"bottleneck\" layer. This can significantly reduce the computational cost of subsequent layers (especially expensive 3x3 or larger convolutions) without drastically sacrificing representational power, as the network can learn the most salient channel-wise combinations to preserve important information.\n",
        "\n",
        "3.  **Dimensionality Expansion:** Conversely, 1x1 convolutions can also increase the number of channels. This can be useful for preparing feature maps for subsequent layers that require a higher dimensionality.\n",
        "\n",
        "4.  **Introducing Non-linearities:** When a non-linear activation function (like ReLU) is applied after a 1x1 convolution, it allows for complex channel-wise feature interactions. This adds another layer of abstraction and learning capacity to the network.\n",
        "\n",
        "5.  **Cross-Channel Feature Pooling:** Although it doesn't pool spatially, a 1x1 convolution can be seen as a form of cross-channel pooling or interaction, where information from different input channels is combined to create new feature representations.\n",
        "\n",
        "**Common Use Cases:**\n",
        "\n",
        "* **Inception Modules (GoogLeNet):** 1x1 convolutions are extensively used for bottlenecking before and after larger spatial convolutions to reduce computational cost.\n",
        "* **ResNet Architectures:** 1x1 convolutions are used in the \"bottleneck blocks\" to reduce the dimensionality before the main 3x3 convolution and then expand it back afterwards.\n",
        "* **Network-in-Network (NiN):** This early architecture heavily utilized 1x1 convolutions as \"multilayer perceptron convolution layers\" to enhance feature abstraction within each spatial location.\n",
        "\n",
        "In summary, 1x1 filters, despite their lack of spatial filtering capability, are powerful tools for manipulating the channel dimension of feature maps, enabling efficient network designs, dimensionality reduction, expansion, and the introduction of additional non-linearities for richer feature learning. They act as a way to perform complex feature engineering across the channel dimension at each spatial point."
      ],
      "metadata": {
        "id": "mi70lSxJP5zh"
      }
    }
  ]
}